{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_WZ7kyM5PdT-"
   },
   "source": [
    "# Clasificación de Sentimientos de Críticas de Películas (utilizando Naive Bayes, Logistic Regression, and Ngrams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ox_Ed43UPdUC"
   },
   "source": [
    "Este notebook es una adaptación del existente en el curso de Fast.ai de procesamiento del lenguaje natural https://github.com/fastai/course-nlp/blob/master/3b-more-details.ipynb\n",
    "\n",
    "Se mostratán las siguientes técnicas de clasificación de sentimientos:\n",
    "\n",
    "- Naive Bayes\n",
    "- Logistic Regression\n",
    "- ngrams\n",
    "\n",
    "Se emplearán las siguientes librerías (no requieren instalación en colab): \n",
    "\n",
    "- *fastai* [the fastai library](https://docs.fast.ai) : Para instalarla utilizar `pip install -U scikit-learn`\n",
    "- *sklearn* [the scikit-learn library](https://scikit-learn.org/stable/user_guide.html):  Para instalarla se aconseja utilizar: `conda install -c pytorch -c fastai fastai=1.0` ó \n",
    "`pip install fastai==1.0`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9Iv4xT_pPdUN"
   },
   "source": [
    "## IMDB dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "khLfEDGoPdUO"
   },
   "source": [
    "Este dataset ([large movie review dataset](http://ai.stanford.edu/~amaas/data/sentiment/))  contiene una colección de 50.000 críticas de IMDB y Fast.ai aloja estos dataset en AWS [fast.ai datasets](https://course.fast.ai/datasets.html). \n",
    "\n",
    "En la versión de fastai, consideraron críticas que tienen una alta polarización:\n",
    "\n",
    "- Una crítica negativa, es aquel que contiene un score ≤ 4/10\n",
    "- Una crítica positiva es aquella que tiene un puntaje ≥ 7/10\n",
    "- No se incluyeron críticas neutrales.\n",
    "\n",
    "\n",
    "Usualmente el dataset - y en este caso se aplica -, está dividido en dos colecciones. \n",
    "- Una de entrenamiento *training* \n",
    "- Otra de pruebas *testing*\n",
    "\n",
    "La tarea de **clasificación de sentimientos** consiste en predecir la polaridad (que tan positivo o que tan negativo es un texto dado).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7BQ_3GW4PdUR"
   },
   "source": [
    "### Imports\n",
    "\n",
    "En esta parte se importarán las librerías a emplear en este notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_LrjaCNjPdUT",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ip31Hr8wPdUe"
   },
   "outputs": [],
   "source": [
    "from fastai import *\n",
    "from fastai.text import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ayDJLWWiPdUj"
   },
   "outputs": [],
   "source": [
    "import sklearn.feature_extraction.text as sklearn_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "t0NLBsXdPdUq"
   },
   "source": [
    "### Tokenización y creación de la matriz de Documento-término"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iPoexLjRPdUq"
   },
   "source": [
    "fast.ai tiene una colección de datasets [datasets hosted via AWS Open Datasets](https://course.fast.ai/datasets.html) para descarga rápida usando URLs. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3MGv8XDePdUs"
   },
   "outputs": [],
   "source": [
    "#?? URLs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lIDkEvaxPdUv"
   },
   "source": [
    "Es una buena idea empezar con un dataset de ejemplo antes de utilizar el dataset completo para realizar cómputos rápidos y hacer que el modelo funcione. Así se puede obtener un dataset de ejemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "cASkpjx7PdUx",
    "outputId": "1eec2c01-d962-4dba-d60f-66d152bfa884"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('C:/Users/Arles/.fastai/data/imdb_sample')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = untar_data(URLs.IMDB_SAMPLE)\n",
    "path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JL-JKU0ePdU3"
   },
   "source": [
    "Es posible apreciar el contenido del dataframe usando pandas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "colab_type": "code",
    "id": "klwWwRBAPdU4",
    "outputId": "d396bea9-4de3-4ae4-beaa-82a7c006438d",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>is_valid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>negative</td>\n",
       "      <td>Un-bleeping-believable! Meg Ryan doesn't even ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>positive</td>\n",
       "      <td>This is a extremely well-made film. The acting...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>negative</td>\n",
       "      <td>Every once in a long while a movie will come a...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>positive</td>\n",
       "      <td>Name just says it all. I watched this movie wi...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>negative</td>\n",
       "      <td>This movie succeeds at being one of the most u...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                               text  is_valid\n",
       "0  negative  Un-bleeping-believable! Meg Ryan doesn't even ...     False\n",
       "1  positive  This is a extremely well-made film. The acting...     False\n",
       "2  negative  Every once in a long while a movie will come a...     False\n",
       "3  positive  Name just says it all. I watched this movie wi...     False\n",
       "4  negative  This movie succeeds at being one of the most u...     False"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(path/'texts.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s0co2Z9MPdU9"
   },
   "source": [
    "En este notebook se utilizará [TextList](https://docs.fast.ai/text.data.html#TextList) que se incluye en la librería fastai:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VJm-6VgSPdU-"
   },
   "outputs": [],
   "source": [
    "movie_reviews = (TextList.from_csv(path, 'texts.csv', cols='text')\n",
    "                         .split_from_df(col=2)\n",
    "                         .label_from_df(cols=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vpBC_XTrPdVC"
   },
   "source": [
    "### Exploración de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6ion6tYIPdVF"
   },
   "source": [
    "Un punto de inicio para cualquier problema que involucre datos es explorarlos y ver como lucen. En este caso vamos a análizar críticas de películas que han sido **etiquetadas** como **positivas** o **negativas.** \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 162
    },
    "colab_type": "code",
    "id": "h_nf6KlyPdVF",
    "outputId": "b93ed6d1-5562-4c05-c368-af503a62f2b7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Text xxbos xxmaj this very funny xxmaj british comedy shows what might happen if a section of xxmaj london , in this case xxmaj xxunk , were to xxunk itself independent from the rest of the xxup uk and its laws , xxunk & post - war xxunk . xxmaj merry xxunk is what would happen . \n",
       "  \n",
       "   xxmaj the explosion of a wartime bomb leads to the xxunk of ancient xxunk which show that xxmaj xxunk was xxunk to the xxmaj xxunk of xxmaj xxunk xxunk ago , a small historical xxunk long since forgotten . xxmaj to the new xxmaj xxunk , however , this is an unexpected opportunity to live as they please , free from any xxunk from xxmaj xxunk . \n",
       "  \n",
       "   xxmaj stanley xxmaj xxunk is excellent as the minor city xxunk who suddenly finds himself leading one of the world 's xxunk xxunk . xxmaj xxunk xxmaj margaret xxmaj xxunk is a delight as the history professor who sides with xxmaj xxunk . xxmaj others in the stand - out cast include xxmaj xxunk xxmaj xxunk , xxmaj paul xxmaj xxunk , xxmaj xxunk xxmaj xxunk , xxmaj xxunk xxmaj xxunk & xxmaj sir xxmaj michael xxmaj xxunk . \n",
       "  \n",
       "   xxmaj welcome to xxmaj xxunk !, Category positive)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_reviews.valid.x[0], movie_reviews.valid.y[0] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4yHEiqhzPdVJ"
   },
   "source": [
    "En NLP, un **token** es la unidad básica de procesamiento (el concepto de token depende de la aplicación y de lo que se quiera realizar). En esta parte, un token hace referencia a palabras o a signos de puntuación y también tendremos algunos tokens especiales que corresponden a palabras desconocidas, mayúsculas, etc.  Los tokens que empiezan con \"xx\" son especiales y son generados por fast.ai. En la ([documentación de fast.ai](https://fastai1.fast.ai/text.transform.html#Tokenizer)) se puede apreciar una lista de tokens y sus significados: \n",
    "\n",
    "![](https://raw.githubusercontent.com/arleserp/CCE2021/main/images/tokens.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "j69Hyfn6PdVJ"
   },
   "source": [
    "Podemos apreciar que el resultado del procesamiento en fast.ai de el dataset de ejemplo genera dos dataset uno de entrenamiento con 800 registros y otro de validación con 200:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "WvNn65JXPdVK",
    "outputId": "306c9740-248f-4f99-fac8-c9e30a7c7576"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800, 200)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(movie_reviews.train.x), len(movie_reviews.valid.x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adicionalmente se generan una lista y un diccionario. La lista incluye un mapeo de enteros a tokens `(movie_reviews.vocab.itos)` y el diccionario mapea de tokens a enteros (`movie_reviews.vocab.stoi`). ¿Por qué cree que son de diferentes tamaños?: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "QJHDH61xPdVQ",
    "outputId": "249c33fc-a171-4468-c44c-a26610b8a5a8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'> <class 'collections.defaultdict'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(6008, 19161)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(type(movie_reviews.vocab.itos), type(movie_reviews.vocab.stoi))\n",
    "len(movie_reviews.vocab.itos), len(movie_reviews.vocab.stoi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VWe3g_xTPdVO"
   },
   "source": [
    "Si miramos que número de token tiene la palabra language:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "O4vJaiSjPdVU",
    "outputId": "d021a67b-fe23-4bd9-e06a-a7c05947f4a4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "917"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_reviews.vocab.stoi['language'] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si miramos la palabra a la que corresponde el token 917:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "78E5NQA-PdVa",
    "outputId": "91319775-9290-4ccc-c314-334853fd3f32"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'language'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_reviews.vocab.itos[917]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las palabras de la 20 a la 29 son:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "O4KRzDSgPdVc",
    "outputId": "c9d14ef1-95aa-4357-8509-e08aae562bc4",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['that', 'this', '\"', \"'s\", '\\n \\n ', '-', 'was', 'as', 'for', 'movie']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_reviews.vocab.itos[20:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La palabra 6007 es:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "yrFVDj9APdVg",
    "outputId": "845fd5f7-5362-4fca-a3ca-2a7e5310abef"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sollett'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_reviews.vocab.itos[6007]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "colab_type": "code",
    "id": "vqQhpYolPdVj",
    "outputId": "4ca73fcc-1c2f-4f63-dd52-fdd0267ffe32"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['xxunk',\n",
       " 'xxpad',\n",
       " 'xxbos',\n",
       " 'xxeos',\n",
       " 'xxfld',\n",
       " 'xxmaj',\n",
       " 'xxup',\n",
       " 'xxrep',\n",
       " 'xxwrep',\n",
       " 'the',\n",
       " '.',\n",
       " ',',\n",
       " 'and',\n",
       " 'a',\n",
       " 'of',\n",
       " 'to',\n",
       " 'is',\n",
       " 'it',\n",
       " 'in',\n",
       " 'i']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_reviews.vocab.itos[:20] #primeras 20 palabras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "Dgzhyjd8PdVn",
    "outputId": "b7bf4582-106c-42a4-fb36-b5ad14851549",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {'xxunk': 0,\n",
       "             'xxpad': 1,\n",
       "             'xxbos': 2,\n",
       "             'xxeos': 3,\n",
       "             'xxfld': 4,\n",
       "             'xxmaj': 5,\n",
       "             'xxup': 6,\n",
       "             'xxrep': 7,\n",
       "             'xxwrep': 8,\n",
       "             'the': 9,\n",
       "             '.': 10,\n",
       "             ',': 11,\n",
       "             'and': 12,\n",
       "             'a': 13,\n",
       "             'of': 14,\n",
       "             'to': 15,\n",
       "             'is': 16,\n",
       "             'it': 17,\n",
       "             'in': 18,\n",
       "             'i': 19,\n",
       "             'that': 20,\n",
       "             'this': 21,\n",
       "             '\"': 22,\n",
       "             \"'s\": 23,\n",
       "             '\\n \\n ': 24,\n",
       "             '-': 25,\n",
       "             'was': 26,\n",
       "             'as': 27,\n",
       "             'for': 28,\n",
       "             'movie': 29,\n",
       "             'with': 30,\n",
       "             'but': 31,\n",
       "             'film': 32,\n",
       "             'you': 33,\n",
       "             ')': 34,\n",
       "             'on': 35,\n",
       "             '(': 36,\n",
       "             \"n't\": 37,\n",
       "             'are': 38,\n",
       "             'he': 39,\n",
       "             'his': 40,\n",
       "             'not': 41,\n",
       "             'have': 42,\n",
       "             'be': 43,\n",
       "             'one': 44,\n",
       "             'they': 45,\n",
       "             'all': 46,\n",
       "             'at': 47,\n",
       "             'by': 48,\n",
       "             'an': 49,\n",
       "             'from': 50,\n",
       "             'like': 51,\n",
       "             '!': 52,\n",
       "             'so': 53,\n",
       "             'who': 54,\n",
       "             'there': 55,\n",
       "             'about': 56,\n",
       "             'just': 57,\n",
       "             'out': 58,\n",
       "             'if': 59,\n",
       "             'or': 60,\n",
       "             'do': 61,\n",
       "             \"'\": 62,\n",
       "             'what': 63,\n",
       "             'her': 64,\n",
       "             'has': 65,\n",
       "             'some': 66,\n",
       "             'more': 67,\n",
       "             'good': 68,\n",
       "             'when': 69,\n",
       "             'up': 70,\n",
       "             'very': 71,\n",
       "             '?': 72,\n",
       "             'she': 73,\n",
       "             'would': 74,\n",
       "             'no': 75,\n",
       "             'really': 76,\n",
       "             'were': 77,\n",
       "             'their': 78,\n",
       "             'my': 79,\n",
       "             'had': 80,\n",
       "             'time': 81,\n",
       "             'can': 82,\n",
       "             'only': 83,\n",
       "             'which': 84,\n",
       "             'even': 85,\n",
       "             'see': 86,\n",
       "             'story': 87,\n",
       "             'me': 88,\n",
       "             'into': 89,\n",
       "             'did': 90,\n",
       "             ':': 91,\n",
       "             'well': 92,\n",
       "             'we': 93,\n",
       "             'will': 94,\n",
       "             'does': 95,\n",
       "             'than': 96,\n",
       "             'also': 97,\n",
       "             'get': 98,\n",
       "             '...': 99,\n",
       "             'people': 100,\n",
       "             'other': 101,\n",
       "             'bad': 102,\n",
       "             'been': 103,\n",
       "             'could': 104,\n",
       "             'first': 105,\n",
       "             'much': 106,\n",
       "             'how': 107,\n",
       "             'most': 108,\n",
       "             'any': 109,\n",
       "             'because': 110,\n",
       "             'two': 111,\n",
       "             'then': 112,\n",
       "             'great': 113,\n",
       "             'him': 114,\n",
       "             'its': 115,\n",
       "             'too': 116,\n",
       "             'made': 117,\n",
       "             'them': 118,\n",
       "             'after': 119,\n",
       "             'movies': 120,\n",
       "             'make': 121,\n",
       "             '/': 122,\n",
       "             'way': 123,\n",
       "             'think': 124,\n",
       "             'never': 125,\n",
       "             'watch': 126,\n",
       "             'acting': 127,\n",
       "             'seen': 128,\n",
       "             ';': 129,\n",
       "             'films': 130,\n",
       "             'plot': 131,\n",
       "             'being': 132,\n",
       "             'many': 133,\n",
       "             'over': 134,\n",
       "             'where': 135,\n",
       "             'character': 136,\n",
       "             'man': 137,\n",
       "             'little': 138,\n",
       "             'better': 139,\n",
       "             'life': 140,\n",
       "             'characters': 141,\n",
       "             'love': 142,\n",
       "             'your': 143,\n",
       "             'here': 144,\n",
       "             'know': 145,\n",
       "             'scenes': 146,\n",
       "             'best': 147,\n",
       "             'end': 148,\n",
       "             'show': 149,\n",
       "             'while': 150,\n",
       "             'through': 151,\n",
       "             'should': 152,\n",
       "             'off': 153,\n",
       "             'ever': 154,\n",
       "             'these': 155,\n",
       "             'go': 156,\n",
       "             'such': 157,\n",
       "             'say': 158,\n",
       "             '--': 159,\n",
       "             'something': 160,\n",
       "             'scene': 161,\n",
       "             'still': 162,\n",
       "             'before': 163,\n",
       "             'though': 164,\n",
       "             'watching': 165,\n",
       "             'between': 166,\n",
       "             'actually': 167,\n",
       "             'old': 168,\n",
       "             '10': 169,\n",
       "             'find': 170,\n",
       "             'back': 171,\n",
       "             'now': 172,\n",
       "             'why': 173,\n",
       "             'years': 174,\n",
       "             \"'ve\": 175,\n",
       "             'actors': 176,\n",
       "             'fact': 177,\n",
       "             'those': 178,\n",
       "             \"'m\": 179,\n",
       "             'thing': 180,\n",
       "             'pretty': 181,\n",
       "             'quite': 182,\n",
       "             'part': 183,\n",
       "             'going': 184,\n",
       "             'same': 185,\n",
       "             'real': 186,\n",
       "             'another': 187,\n",
       "             'down': 188,\n",
       "             'funny': 189,\n",
       "             'nothing': 190,\n",
       "             'look': 191,\n",
       "             'makes': 192,\n",
       "             '*': 193,\n",
       "             'new': 194,\n",
       "             'want': 195,\n",
       "             'action': 196,\n",
       "             '&': 197,\n",
       "             'director': 198,\n",
       "             'work': 199,\n",
       "             'few': 200,\n",
       "             \"'re\": 201,\n",
       "             'seems': 202,\n",
       "             'around': 203,\n",
       "             'world': 204,\n",
       "             'point': 205,\n",
       "             'without': 206,\n",
       "             'cast': 207,\n",
       "             'again': 208,\n",
       "             'own': 209,\n",
       "             'both': 210,\n",
       "             'lot': 211,\n",
       "             'enough': 212,\n",
       "             'every': 213,\n",
       "             'family': 214,\n",
       "             'got': 215,\n",
       "             'ca': 216,\n",
       "             \"'ll\": 217,\n",
       "             'probably': 218,\n",
       "             'big': 219,\n",
       "             'bit': 220,\n",
       "             'might': 221,\n",
       "             'things': 222,\n",
       "             'horror': 223,\n",
       "             'us': 224,\n",
       "             'almost': 225,\n",
       "             'may': 226,\n",
       "             'right': 227,\n",
       "             'must': 228,\n",
       "             'away': 229,\n",
       "             'thought': 230,\n",
       "             'interesting': 231,\n",
       "             'least': 232,\n",
       "             'whole': 233,\n",
       "             'series': 234,\n",
       "             'gets': 235,\n",
       "             'each': 236,\n",
       "             'give': 237,\n",
       "             'young': 238,\n",
       "             'however': 239,\n",
       "             'making': 240,\n",
       "             'day': 241,\n",
       "             'fun': 242,\n",
       "             'anything': 243,\n",
       "             'minutes': 244,\n",
       "             'kind': 245,\n",
       "             'come': 246,\n",
       "             'girl': 247,\n",
       "             'saw': 248,\n",
       "             'script': 249,\n",
       "             'take': 250,\n",
       "             'long': 251,\n",
       "             'times': 252,\n",
       "             'someone': 253,\n",
       "             'found': 254,\n",
       "             'done': 255,\n",
       "             'feel': 256,\n",
       "             'far': 257,\n",
       "             'since': 258,\n",
       "             'role': 259,\n",
       "             'original': 260,\n",
       "             'course': 261,\n",
       "             'goes': 262,\n",
       "             'last': 263,\n",
       "             'true': 264,\n",
       "             'simply': 265,\n",
       "             'always': 266,\n",
       "             \"'d\": 267,\n",
       "             'tv': 268,\n",
       "             'hard': 269,\n",
       "             'place': 270,\n",
       "             'set': 271,\n",
       "             'trying': 272,\n",
       "             'believe': 273,\n",
       "             'shot': 274,\n",
       "             'comes': 275,\n",
       "             'actor': 276,\n",
       "             'yet': 277,\n",
       "             '4': 278,\n",
       "             'having': 279,\n",
       "             'book': 280,\n",
       "             'looks': 281,\n",
       "             'guy': 282,\n",
       "             'screen': 283,\n",
       "             'later': 284,\n",
       "             'shows': 285,\n",
       "             'performance': 286,\n",
       "             'worth': 287,\n",
       "             'comedy': 288,\n",
       "             'sure': 289,\n",
       "             'looking': 290,\n",
       "             'sense': 291,\n",
       "             'star': 292,\n",
       "             'effects': 293,\n",
       "             'read': 294,\n",
       "             'takes': 295,\n",
       "             'although': 296,\n",
       "             'audience': 297,\n",
       "             'ending': 298,\n",
       "             'john': 299,\n",
       "             'anyone': 300,\n",
       "             'worst': 301,\n",
       "             'american': 302,\n",
       "             'year': 303,\n",
       "             'especially': 304,\n",
       "             'women': 305,\n",
       "             'together': 306,\n",
       "             'dvd': 307,\n",
       "             'instead': 308,\n",
       "             'different': 309,\n",
       "             'am': 310,\n",
       "             'woman': 311,\n",
       "             'men': 312,\n",
       "             '2': 313,\n",
       "             'our': 314,\n",
       "             'played': 315,\n",
       "             'music': 316,\n",
       "             'special': 317,\n",
       "             'three': 318,\n",
       "             'rest': 319,\n",
       "             'put': 320,\n",
       "             'maybe': 321,\n",
       "             'wife': 322,\n",
       "             'kids': 323,\n",
       "             'war': 324,\n",
       "             'left': 325,\n",
       "             'black': 326,\n",
       "             'once': 327,\n",
       "             'second': 328,\n",
       "             'watched': 329,\n",
       "             'next': 330,\n",
       "             'friends': 331,\n",
       "             'rather': 332,\n",
       "             'let': 333,\n",
       "             '\\x96': 334,\n",
       "             'job': 335,\n",
       "             'start': 336,\n",
       "             'others': 337,\n",
       "             'budget': 338,\n",
       "             'need': 339,\n",
       "             'mind': 340,\n",
       "             'said': 341,\n",
       "             'main': 342,\n",
       "             'else': 343,\n",
       "             'wrong': 344,\n",
       "             'beautiful': 345,\n",
       "             'half': 346,\n",
       "             'high': 347,\n",
       "             'idea': 348,\n",
       "             'death': 349,\n",
       "             'tell': 350,\n",
       "             'help': 351,\n",
       "             'nice': 352,\n",
       "             'seem': 353,\n",
       "             'perhaps': 354,\n",
       "             'hollywood': 355,\n",
       "             'everyone': 356,\n",
       "             'play': 357,\n",
       "             'case': 358,\n",
       "             'production': 359,\n",
       "             'piece': 360,\n",
       "             'episode': 361,\n",
       "             'camera': 362,\n",
       "             'low': 363,\n",
       "             'already': 364,\n",
       "             'top': 365,\n",
       "             'poor': 366,\n",
       "             'during': 367,\n",
       "             '3': 368,\n",
       "             'stars': 369,\n",
       "             'house': 370,\n",
       "             '..': 371,\n",
       "             'couple': 372,\n",
       "             'boring': 373,\n",
       "             'reason': 374,\n",
       "             'try': 375,\n",
       "             'along': 376,\n",
       "             'name': 377,\n",
       "             'small': 378,\n",
       "             'plays': 379,\n",
       "             'father': 380,\n",
       "             'everything': 381,\n",
       "             'used': 382,\n",
       "             'video': 383,\n",
       "             'getting': 384,\n",
       "             'money': 385,\n",
       "             'full': 386,\n",
       "             'less': 387,\n",
       "             'performances': 388,\n",
       "             'often': 389,\n",
       "             'liked': 390,\n",
       "             'came': 391,\n",
       "             '1': 392,\n",
       "             'robert': 393,\n",
       "             'either': 394,\n",
       "             'fan': 395,\n",
       "             'given': 396,\n",
       "             'hand': 397,\n",
       "             'kill': 398,\n",
       "             'felt': 399,\n",
       "             'yes': 400,\n",
       "             'completely': 401,\n",
       "             'night': 402,\n",
       "             'children': 403,\n",
       "             'himself': 404,\n",
       "             'girls': 405,\n",
       "             'early': 406,\n",
       "             'awful': 407,\n",
       "             'oh': 408,\n",
       "             'live': 409,\n",
       "             'picture': 410,\n",
       "             'parts': 411,\n",
       "             'throughout': 412,\n",
       "             'until': 413,\n",
       "             'become': 414,\n",
       "             'town': 415,\n",
       "             'written': 416,\n",
       "             'terrible': 417,\n",
       "             'turn': 418,\n",
       "             'child': 419,\n",
       "             'despite': 420,\n",
       "             'moments': 421,\n",
       "             'boy': 422,\n",
       "             'problem': 423,\n",
       "             'head': 424,\n",
       "             'stupid': 425,\n",
       "             'beginning': 426,\n",
       "             'home': 427,\n",
       "             'version': 428,\n",
       "             'able': 429,\n",
       "             'excellent': 430,\n",
       "             'sometimes': 431,\n",
       "             'overall': 432,\n",
       "             'recommend': 433,\n",
       "             'sex': 434,\n",
       "             'keep': 435,\n",
       "             'human': 436,\n",
       "             'drama': 437,\n",
       "             'hero': 438,\n",
       "             'supposed': 439,\n",
       "             'seemed': 440,\n",
       "             'use': 441,\n",
       "             'writing': 442,\n",
       "             'wo': 443,\n",
       "             'remember': 444,\n",
       "             'went': 445,\n",
       "             'enjoy': 446,\n",
       "             'classic': 447,\n",
       "             'person': 448,\n",
       "             'killer': 449,\n",
       "             'lost': 450,\n",
       "             'late': 451,\n",
       "             '5': 452,\n",
       "             'title': 453,\n",
       "             'king': 454,\n",
       "             'entire': 455,\n",
       "             'history': 456,\n",
       "             'son': 457,\n",
       "             'school': 458,\n",
       "             'lead': 459,\n",
       "             'english': 460,\n",
       "             'sound': 461,\n",
       "             'cinema': 462,\n",
       "             'seeing': 463,\n",
       "             'unfortunately': 464,\n",
       "             'genre': 465,\n",
       "             'sort': 466,\n",
       "             'mean': 467,\n",
       "             'friend': 468,\n",
       "             'fans': 469,\n",
       "             'close': 470,\n",
       "             'quality': 471,\n",
       "             'definitely': 472,\n",
       "             'james': 473,\n",
       "             'worse': 474,\n",
       "             'says': 475,\n",
       "             'except': 476,\n",
       "             'doing': 477,\n",
       "             'itself': 478,\n",
       "             'past': 479,\n",
       "             'certainly': 480,\n",
       "             'days': 481,\n",
       "             'five': 482,\n",
       "             'dialogue': 483,\n",
       "             'line': 484,\n",
       "             'anyway': 485,\n",
       "             'under': 486,\n",
       "             'tries': 487,\n",
       "             'called': 488,\n",
       "             'fine': 489,\n",
       "             'guys': 490,\n",
       "             'care': 491,\n",
       "             'style': 492,\n",
       "             'hope': 493,\n",
       "             'short': 494,\n",
       "             'lines': 495,\n",
       "             'told': 496,\n",
       "             'car': 497,\n",
       "             'decent': 498,\n",
       "             'brother': 499,\n",
       "             'killed': 500,\n",
       "             'wanted': 501,\n",
       "             'entertaining': 502,\n",
       "             'based': 503,\n",
       "             'absolutely': 504,\n",
       "             'feeling': 505,\n",
       "             'truly': 506,\n",
       "             'etc': 507,\n",
       "             'heard': 508,\n",
       "             'serious': 509,\n",
       "             'run': 510,\n",
       "             'wonderful': 511,\n",
       "             'lives': 512,\n",
       "             'gives': 513,\n",
       "             'moment': 514,\n",
       "             'game': 515,\n",
       "             'documentary': 516,\n",
       "             'self': 517,\n",
       "             'several': 518,\n",
       "             'waste': 519,\n",
       "             'dead': 520,\n",
       "             'blood': 521,\n",
       "             'matter': 522,\n",
       "             'wonder': 523,\n",
       "             'humor': 524,\n",
       "             'thinking': 525,\n",
       "             'against': 526,\n",
       "             'white': 527,\n",
       "             'side': 528,\n",
       "             'works': 529,\n",
       "             'mother': 530,\n",
       "             'flick': 531,\n",
       "             'stuff': 532,\n",
       "             'turns': 533,\n",
       "             'finally': 534,\n",
       "             'loved': 535,\n",
       "             'group': 536,\n",
       "             'wants': 537,\n",
       "             'face': 538,\n",
       "             'guess': 539,\n",
       "             'dark': 540,\n",
       "             'city': 541,\n",
       "             'events': 542,\n",
       "             'starts': 543,\n",
       "             'hour': 544,\n",
       "             'took': 545,\n",
       "             'george': 546,\n",
       "             'themselves': 547,\n",
       "             'red': 548,\n",
       "             'behind': 549,\n",
       "             'talking': 550,\n",
       "             'hit': 551,\n",
       "             'eyes': 552,\n",
       "             'attempt': 553,\n",
       "             'direction': 554,\n",
       "             'novel': 555,\n",
       "             'saying': 556,\n",
       "             'word': 557,\n",
       "             'dull': 558,\n",
       "             'light': 559,\n",
       "             'view': 560,\n",
       "             'playing': 561,\n",
       "             'opinion': 562,\n",
       "             'expect': 563,\n",
       "             'evil': 564,\n",
       "             'ten': 565,\n",
       "             'violence': 566,\n",
       "             'local': 567,\n",
       "             'final': 568,\n",
       "             'gave': 569,\n",
       "             'leave': 570,\n",
       "             'paul': 571,\n",
       "             'crap': 572,\n",
       "             'happens': 573,\n",
       "             'knows': 574,\n",
       "             'problems': 575,\n",
       "             'example': 576,\n",
       "             'relationship': 577,\n",
       "             'non': 578,\n",
       "             'michael': 579,\n",
       "             'victor': 580,\n",
       "             'ridiculous': 581,\n",
       "             'god': 582,\n",
       "             'similar': 583,\n",
       "             'general': 584,\n",
       "             'major': 585,\n",
       "             'bunch': 586,\n",
       "             'sister': 587,\n",
       "             'oscar': 588,\n",
       "             'turned': 589,\n",
       "             'brilliant': 590,\n",
       "             'highly': 591,\n",
       "             'nearly': 592,\n",
       "             'de': 593,\n",
       "             'please': 594,\n",
       "             'romance': 595,\n",
       "             'body': 596,\n",
       "             'extremely': 597,\n",
       "             'mr.': 598,\n",
       "             'soon': 599,\n",
       "             'yourself': 600,\n",
       "             'known': 601,\n",
       "             'lack': 602,\n",
       "             'age': 603,\n",
       "             'interest': 604,\n",
       "             'ago': 605,\n",
       "             'stories': 606,\n",
       "             'exactly': 607,\n",
       "             'finds': 608,\n",
       "             'modern': 609,\n",
       "             'voice': 610,\n",
       "             'perfect': 611,\n",
       "             'heart': 612,\n",
       "             'alone': 613,\n",
       "             'tells': 614,\n",
       "             'daughter': 615,\n",
       "             'directed': 616,\n",
       "             'needs': 617,\n",
       "             'kid': 618,\n",
       "             'lady': 619,\n",
       "             'sad': 620,\n",
       "             'fight': 621,\n",
       "             'happened': 622,\n",
       "             'eye': 623,\n",
       "             'favorite': 624,\n",
       "             'using': 625,\n",
       "             'upon': 626,\n",
       "             'ben': 627,\n",
       "             'none': 628,\n",
       "             'beyond': 629,\n",
       "             'nature': 630,\n",
       "             'change': 631,\n",
       "             'save': 632,\n",
       "             'shots': 633,\n",
       "             'country': 634,\n",
       "             'number': 635,\n",
       "             'shown': 636,\n",
       "             'surprised': 637,\n",
       "             'romantic': 638,\n",
       "             'huge': 639,\n",
       "             'murder': 640,\n",
       "             'steve': 641,\n",
       "             'slow': 642,\n",
       "             'myself': 643,\n",
       "             'woods': 644,\n",
       "             'apparently': 645,\n",
       "             'lake': 646,\n",
       "             'cheap': 647,\n",
       "             'involved': 648,\n",
       "             'roles': 649,\n",
       "             '6': 650,\n",
       "             'gore': 651,\n",
       "             'obviously': 652,\n",
       "             'knew': 653,\n",
       "             'level': 654,\n",
       "             '8': 655,\n",
       "             'experience': 656,\n",
       "             'became': 657,\n",
       "             'gone': 658,\n",
       "             'cover': 659,\n",
       "             'amazing': 660,\n",
       "             'create': 661,\n",
       "             'living': 662,\n",
       "             'usually': 663,\n",
       "             'order': 664,\n",
       "             'monster': 665,\n",
       "             'happen': 666,\n",
       "             'list': 667,\n",
       "             'clearly': 668,\n",
       "             'power': 669,\n",
       "             'features': 670,\n",
       "             're': 671,\n",
       "             'subject': 672,\n",
       "             'across': 673,\n",
       "             'parents': 674,\n",
       "             'seriously': 675,\n",
       "             'ways': 676,\n",
       "             'room': 677,\n",
       "             'filmed': 678,\n",
       "             'cheesy': 679,\n",
       "             'disappointed': 680,\n",
       "             'important': 681,\n",
       "             'plenty': 682,\n",
       "             '7': 683,\n",
       "             'particular': 684,\n",
       "             'started': 685,\n",
       "             'today': 686,\n",
       "             'enjoyed': 687,\n",
       "             'cinematography': 688,\n",
       "             'annoying': 689,\n",
       "             'looked': 690,\n",
       "             'supporting': 691,\n",
       "             'mostly': 692,\n",
       "             'message': 693,\n",
       "             'somewhat': 694,\n",
       "             'viewer': 695,\n",
       "             'type': 696,\n",
       "             'certain': 697,\n",
       "             'release': 698,\n",
       "             'effort': 699,\n",
       "             'possible': 700,\n",
       "             'add': 701,\n",
       "             'figure': 702,\n",
       "             'named': 703,\n",
       "             'wish': 704,\n",
       "             'difficult': 705,\n",
       "             'falls': 706,\n",
       "             'four': 707,\n",
       "             'husband': 708,\n",
       "             'score': 709,\n",
       "             'leads': 710,\n",
       "             'form': 711,\n",
       "             'working': 712,\n",
       "             'writer': 713,\n",
       "             'sets': 714,\n",
       "             'including': 715,\n",
       "             'enjoyable': 716,\n",
       "             'ok': 717,\n",
       "             'note': 718,\n",
       "             'spent': 719,\n",
       "             'review': 720,\n",
       "             'art': 721,\n",
       "             'police': 722,\n",
       "             'sit': 723,\n",
       "             'horrible': 724,\n",
       "             'actress': 725,\n",
       "             'ones': 726,\n",
       "             'bring': 727,\n",
       "             'greatest': 728,\n",
       "             'dance': 729,\n",
       "             'earth': 730,\n",
       "             'becomes': 731,\n",
       "             'happy': 732,\n",
       "             'cut': 733,\n",
       "             'straight': 734,\n",
       "             'soundtrack': 735,\n",
       "             'leading': 736,\n",
       "             'laugh': 737,\n",
       "             'strange': 738,\n",
       "             'space': 739,\n",
       "             'b': 740,\n",
       "             'tale': 741,\n",
       "             'comic': 742,\n",
       "             'near': 743,\n",
       "             'due': 744,\n",
       "             'weak': 745,\n",
       "             'earlier': 746,\n",
       "             'follow': 747,\n",
       "             'british': 748,\n",
       "             'ends': 749,\n",
       "             'typical': 750,\n",
       "             'attention': 751,\n",
       "             'points': 752,\n",
       "             'talent': 753,\n",
       "             'tom': 754,\n",
       "             'female': 755,\n",
       "             'future': 756,\n",
       "             'fall': 757,\n",
       "             'laughs': 758,\n",
       "             'stop': 759,\n",
       "             'easy': 760,\n",
       "             'moving': 761,\n",
       "             'apart': 762,\n",
       "             'chance': 763,\n",
       "             'running': 764,\n",
       "             'york': 765,\n",
       "             'particularly': 766,\n",
       "             'luke': 767,\n",
       "             'bill': 768,\n",
       "             'forced': 769,\n",
       "             'theme': 770,\n",
       "             'rating': 771,\n",
       "             'coming': 772,\n",
       "             'davis': 773,\n",
       "             'totally': 774,\n",
       "             'realistic': 775,\n",
       "             'simple': 776,\n",
       "             'hours': 777,\n",
       "             'taken': 778,\n",
       "             'indeed': 779,\n",
       "             'released': 780,\n",
       "             'sexual': 781,\n",
       "             'feels': 782,\n",
       "             'french': 783,\n",
       "             'screenplay': 784,\n",
       "             'la': 785,\n",
       "             'jokes': 786,\n",
       "             'sequences': 787,\n",
       "             'chase': 788,\n",
       "             'portrayed': 789,\n",
       "             'dramatic': 790,\n",
       "             'mention': 791,\n",
       "             'talk': 792,\n",
       "             'gun': 793,\n",
       "             'thriller': 794,\n",
       "             'jimmy': 795,\n",
       "             'career': 796,\n",
       "             'reality': 797,\n",
       "             'incredibly': 798,\n",
       "             'whether': 799,\n",
       "             'towards': 800,\n",
       "             'easily': 801,\n",
       "             'entertainment': 802,\n",
       "             'feature': 803,\n",
       "             'western': 804,\n",
       "             'dialog': 805,\n",
       "             'business': 806,\n",
       "             'suspense': 807,\n",
       "             'focus': 808,\n",
       "             'doubt': 809,\n",
       "             'possibly': 810,\n",
       "             'water': 811,\n",
       "             'gay': 812,\n",
       "             'blob': 813,\n",
       "             'comments': 814,\n",
       "             'brothers': 815,\n",
       "             'clear': 816,\n",
       "             'agree': 817,\n",
       "             'allen': 818,\n",
       "             'door': 819,\n",
       "             'editing': 820,\n",
       "             'third': 821,\n",
       "             'deserves': 822,\n",
       "             'silly': 823,\n",
       "             'fantastic': 824,\n",
       "             'convincing': 825,\n",
       "             'hardly': 826,\n",
       "             'lame': 827,\n",
       "             'act': 828,\n",
       "             'former': 829,\n",
       "             'material': 830,\n",
       "             'appears': 831,\n",
       "             'understand': 832,\n",
       "             'twist': 833,\n",
       "             'episodes': 834,\n",
       "             'buy': 835,\n",
       "             'secret': 836,\n",
       "             'richard': 837,\n",
       "             'south': 838,\n",
       "             'bourne': 839,\n",
       "             'deal': 840,\n",
       "             'musical': 841,\n",
       "             'words': 842,\n",
       "             'unique': 843,\n",
       "             'mess': 844,\n",
       "             'opening': 845,\n",
       "             'society': 846,\n",
       "             'avoid': 847,\n",
       "             'footage': 848,\n",
       "             'joe': 849,\n",
       "             'free': 850,\n",
       "             'forget': 851,\n",
       "             'herself': 852,\n",
       "             'appear': 853,\n",
       "             'obvious': 854,\n",
       "             'box': 855,\n",
       "             'single': 856,\n",
       "             'average': 857,\n",
       "             'indian': 858,\n",
       "             'rent': 859,\n",
       "             'okay': 860,\n",
       "             'scary': 861,\n",
       "             'within': 862,\n",
       "             'office': 863,\n",
       "             'crime': 864,\n",
       "             'science': 865,\n",
       "             '80': 866,\n",
       "             'believable': 867,\n",
       "             'period': 868,\n",
       "             'showing': 869,\n",
       "             'call': 870,\n",
       "             'return': 871,\n",
       "             'keeps': 872,\n",
       "             'lee': 873,\n",
       "             'expected': 874,\n",
       "             'stay': 875,\n",
       "             'middle': 876,\n",
       "             'jack': 877,\n",
       "             'hands': 878,\n",
       "             'david': 879,\n",
       "             'attempts': 880,\n",
       "             'strong': 881,\n",
       "             'tension': 882,\n",
       "             'crew': 883,\n",
       "             'hilarious': 884,\n",
       "             'grade': 885,\n",
       "             'outside': 886,\n",
       "             'means': 887,\n",
       "             'viewing': 888,\n",
       "             'sadly': 889,\n",
       "             'hell': 890,\n",
       "             'whatever': 891,\n",
       "             'sorry': 892,\n",
       "             'recently': 893,\n",
       "             'stage': 894,\n",
       "             'decides': 895,\n",
       "             'hear': 896,\n",
       "             'team': 897,\n",
       "             'learn': 898,\n",
       "             'nor': 899,\n",
       "             'open': 900,\n",
       "             'break': 901,\n",
       "             'question': 902,\n",
       "             'remake': 903,\n",
       "             'porn': 904,\n",
       "             'pain': 905,\n",
       "             'imagine': 906,\n",
       "             'deep': 907,\n",
       "             'zombie': 908,\n",
       "             'basically': 909,\n",
       "             'killing': 910,\n",
       "             'company': 911,\n",
       "             'poorly': 912,\n",
       "             'dr.': 913,\n",
       "             'predictable': 914,\n",
       "             'taking': 915,\n",
       "             'large': 916,\n",
       "             'language': 917,\n",
       "             'giving': 918,\n",
       "             'public': 919,\n",
       "             'audiences': 920,\n",
       "             'ask': 921,\n",
       "             'cool': 922,\n",
       "             'america': 923,\n",
       "             'slasher': 924,\n",
       "             'west': 925,\n",
       "             'mentioned': 926,\n",
       "             'die': 927,\n",
       "             'christmas': 928,\n",
       "             'complete': 929,\n",
       "             'needed': 930,\n",
       "             'martin': 931,\n",
       "             'cgi': 932,\n",
       "             'boys': 933,\n",
       "             'vargas': 934,\n",
       "             'usual': 935,\n",
       "             'begin': 936,\n",
       "             'dad': 937,\n",
       "             'total': 938,\n",
       "             'somehow': 939,\n",
       "             'stick': 940,\n",
       "             'shame': 941,\n",
       "             'successful': 942,\n",
       "             'sitting': 943,\n",
       "             'fred': 944,\n",
       "             'meets': 945,\n",
       "             'unless': 946,\n",
       "             'dancing': 947,\n",
       "             'sounds': 948,\n",
       "             'above': 949,\n",
       "             'elements': 950,\n",
       "             'whose': 951,\n",
       "             'german': 952,\n",
       "             'considering': 953,\n",
       "             'caught': 954,\n",
       "             'credit': 955,\n",
       "             'interested': 956,\n",
       "             'move': 957,\n",
       "             'filming': 958,\n",
       "             'truth': 959,\n",
       "             'eventually': 960,\n",
       "             'share': 961,\n",
       "             'ability': 962,\n",
       "             'meaning': 963,\n",
       "             'agent': 964,\n",
       "             'fast': 965,\n",
       "             'stand': 966,\n",
       "             'onto': 967,\n",
       "             'plain': 968,\n",
       "             'comment': 969,\n",
       "             'kept': 970,\n",
       "             'situation': 971,\n",
       "             'setting': 972,\n",
       "             'value': 973,\n",
       "             'willing': 974,\n",
       "             'realize': 975,\n",
       "             'acted': 976,\n",
       "             'weird': 977,\n",
       "             'alive': 978,\n",
       "             'fairly': 979,\n",
       "             'dream': 980,\n",
       "             'building': 981,\n",
       "             'hair': 982,\n",
       "             'bored': 983,\n",
       "             'minute': 984,\n",
       "             'emotional': 985,\n",
       "             'directing': 986,\n",
       "             'theatrical': 987,\n",
       "             'famous': 988,\n",
       "             'begins': 989,\n",
       "             'front': 990,\n",
       "             'catch': 991,\n",
       "             'sequence': 992,\n",
       "             'runs': 993,\n",
       "             'follows': 994,\n",
       "             'song': 995,\n",
       "             'government': 996,\n",
       "             'miss': 997,\n",
       "             'actual': 998,\n",
       "             'makers': 999,\n",
       "             ...})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_reviews.vocab.stoi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FyoeuqoDPdVs"
   },
   "source": [
    "Let's test that a non-word maps to xxunk:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "D3_afX_rPdVt",
    "outputId": "3f190a42-d42b-410e-88e4-2fa2c6396d69"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'xxunk'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_reviews.vocab.itos[movie_reviews.vocab.stoi['rrachell']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "gG_9Eu9ZPdVw",
    "outputId": "5b3e2766-8e82-4a2e-f56a-21f742691df2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'language'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_reviews.vocab.itos[movie_reviews.vocab.stoi['language']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L0ndoJhBPdVz"
   },
   "outputs": [],
   "source": [
    "t = movie_reviews.train[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "4dz-fhY4PdV2",
    "outputId": "b8530aab-62c9-47cb-c428-ea7b7eade2f6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   2,    5, 4619,   25,    0,   25,  867,   52,    5, 3776,    5, 1800,   95,   37,   85,  191,   64,  935,\n",
       "          0, 2738,  517,   18,   21,   11,   84, 2417,  192,   88, 3777,   64], dtype=int64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.data[:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "p-Z4cbk9PdV5"
   },
   "source": [
    "## Creación manual de nuestra matriz de término-documento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4dmxxiSHPdV5"
   },
   "source": [
    "Esta matriz representa una bolsa de palabras. No se mantiene un registro de como las palabras están ordenadas, solamente cuales palabras ocurren y que tan a menudo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "drEjFeGJPdV7"
   },
   "source": [
    "Es posible utilizar [sklearn's CountVectorizer](https://github.com/scikit-learn/scikit-learn/blob/55bf5d9/sklearn/feature_extraction/text.py#L940). En este notebook se creará de forma manual para:\n",
    "- entender lo que sklearn está haciendo por debajo\n",
    "- crear algo que se integre con TextList de fastai\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qaGh7nmVPdV9"
   },
   "source": [
    "Para crear esta matriz es necesario entender un poco como funcionan los **Counter** de python y las matrices **dispersas**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "atjaHtxAPdV-"
   },
   "source": [
    "### Counters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2rzy2VvcPdV_"
   },
   "source": [
    "Un counter permite contar la cantidad de ocurrencias de una lista."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ucS_GIbQPdWB"
   },
   "outputs": [],
   "source": [
    "c = Counter([4,2,8,8,4,8]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "F-DJparGPdWF",
    "outputId": "664a510e-f910-4dcb-d868-69615f6ede9a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({4: 2, 2: 1, 8: 3})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "Rskt-gJGPdWI",
    "outputId": "7107044a-0949-40a2-e685-4a02de1cb102"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values([2, 1, 3])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "Sfi14BQIPdWL",
    "outputId": "2e94824f-56de-43f4-e186-b9754754635c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([4, 2, 8])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2k2qITNhPdWN"
   },
   "source": [
    "Counter pertenece al modulo de collections de python (como OrderedDict, defaultdict, deque, and namedtuple)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pKcoO5DsPdWO"
   },
   "source": [
    "### Matrices disperas en Scipy (in Scipy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SIuF4NxCPdWO"
   },
   "source": [
    "Aunque se han reducido de 19.000 palabras a 6000. La mayoría de los token no aparecen en la mayoría de críticas. Esto nos permite tomar ventaja y almacenar los datos en una **matriz dispersa**.\n",
    "\n",
    "- Una matriz con muchos ceros es dispersa (**sparse**)\n",
    "- Lo opuesto a una matriz dispersa es una matriz densa (**dense**)\n",
    "- Para optimizar memoria es posible guardar únicamente los datos que no son cero\n",
    "\n",
    "Para ahorrar memoria se utilizan las matrices dispersas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IZtkxhCBPdWP"
   },
   "source": [
    "\n",
    "<img src=\"https://dziganto.github.io/assets/images/sparse_matrix.png?raw=true\" alt=\"floating point\" style=\"width: 30%\"/>\n",
    "\n",
    "Otro ejemplo de una matriz dispersa grande:\n",
    "\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/8/8a/Finite_element_sparse_matrix.png\" tyle=\"width: 20%\"/>\n",
    "\n",
    "[Source](https://commons.wikimedia.org/w/index.php?curid=2245335)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RroLAY0qPdWQ"
   },
   "source": [
    "Los formatos más comunes de almacenamiento de matrices dispersas son:\n",
    "- coordinate-wise (scipy calls COO)\n",
    "- compressed sparse row (CSR) *\n",
    "- compressed sparse column (CSC)\n",
    "\n",
    "[Aquí algumnos ejemplos](http://www.mathcs.emory.edu/~cheung/Courses/561/Syllabus/3-C/sparse.html)\n",
    "\n",
    "[Aquí muchos otros formatos](http://www.cs.colostate.edu/~mcrob/toolbox/c++/sparseMatrix/sparse_matrix_compression.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Tl_siBqDPdWR"
   },
   "source": [
    "### Nuestro CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "Ti51CNKePdWT",
    "outputId": "de532fd3-2f01-4c45-f621-3c72ac854f91"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({2: 1,\n",
       "         5: 32,\n",
       "         21: 3,\n",
       "         71: 1,\n",
       "         189: 1,\n",
       "         748: 1,\n",
       "         288: 1,\n",
       "         285: 1,\n",
       "         63: 2,\n",
       "         221: 1,\n",
       "         666: 2,\n",
       "         59: 1,\n",
       "         13: 4,\n",
       "         2705: 1,\n",
       "         14: 6,\n",
       "         2875: 1,\n",
       "         11: 10,\n",
       "         18: 2,\n",
       "         358: 1,\n",
       "         0: 32,\n",
       "         77: 1,\n",
       "         15: 6,\n",
       "         478: 1,\n",
       "         1833: 1,\n",
       "         50: 3,\n",
       "         9: 10,\n",
       "         319: 1,\n",
       "         6: 1,\n",
       "         2743: 1,\n",
       "         12: 1,\n",
       "         115: 1,\n",
       "         4126: 1,\n",
       "         197: 2,\n",
       "         1331: 1,\n",
       "         25: 2,\n",
       "         324: 1,\n",
       "         10: 7,\n",
       "         3963: 1,\n",
       "         16: 4,\n",
       "         74: 1,\n",
       "         24: 3,\n",
       "         2817: 1,\n",
       "         5821: 1,\n",
       "         2595: 1,\n",
       "         710: 1,\n",
       "         3429: 1,\n",
       "         84: 1,\n",
       "         149: 1,\n",
       "         20: 1,\n",
       "         26: 1,\n",
       "         605: 1,\n",
       "         378: 1,\n",
       "         1057: 1,\n",
       "         251: 1,\n",
       "         258: 1,\n",
       "         1346: 1,\n",
       "         194: 1,\n",
       "         239: 1,\n",
       "         49: 1,\n",
       "         2764: 1,\n",
       "         1335: 1,\n",
       "         409: 1,\n",
       "         27: 3,\n",
       "         45: 1,\n",
       "         594: 1,\n",
       "         850: 1,\n",
       "         109: 1,\n",
       "         2601: 1,\n",
       "         430: 1,\n",
       "         1902: 1,\n",
       "         541: 1,\n",
       "         54: 2,\n",
       "         1107: 1,\n",
       "         608: 1,\n",
       "         404: 1,\n",
       "         736: 1,\n",
       "         44: 1,\n",
       "         204: 1,\n",
       "         23: 1,\n",
       "         3480: 1,\n",
       "         4736: 1,\n",
       "         456: 1,\n",
       "         4051: 1,\n",
       "         2420: 1,\n",
       "         30: 1,\n",
       "         337: 1,\n",
       "         966: 1,\n",
       "         58: 1,\n",
       "         207: 1,\n",
       "         2110: 1,\n",
       "         571: 1,\n",
       "         5035: 1,\n",
       "         579: 1,\n",
       "         1843: 1,\n",
       "         52: 1})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter((movie_reviews.valid.x)[0].data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "lHbhR6n6PdWU",
    "outputId": "6cdb92b9-0596-45e8-94f6-d8900b38ffa4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'very'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_reviews.vocab.itos[71]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 126
    },
    "colab_type": "code",
    "id": "xi-XRV3sPdWX",
    "outputId": "99abd2f8-377a-410f-fe4b-ef4eb400622e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text xxbos xxmaj this very funny xxmaj british comedy shows what might happen if a section of xxmaj london , in this case xxmaj xxunk , were to xxunk itself independent from the rest of the xxup uk and its laws , xxunk & post - war xxunk . xxmaj merry xxunk is what would happen . \n",
       " \n",
       "  xxmaj the explosion of a wartime bomb leads to the xxunk of ancient xxunk which show that xxmaj xxunk was xxunk to the xxmaj xxunk of xxmaj xxunk xxunk ago , a small historical xxunk long since forgotten . xxmaj to the new xxmaj xxunk , however , this is an unexpected opportunity to live as they please , free from any xxunk from xxmaj xxunk . \n",
       " \n",
       "  xxmaj stanley xxmaj xxunk is excellent as the minor city xxunk who suddenly finds himself leading one of the world 's xxunk xxunk . xxmaj xxunk xxmaj margaret xxmaj xxunk is a delight as the history professor who sides with xxmaj xxunk . xxmaj others in the stand - out cast include xxmaj xxunk xxmaj xxunk , xxmaj paul xxmaj xxunk , xxmaj xxunk xxmaj xxunk , xxmaj xxunk xxmaj xxunk & xxmaj sir xxmaj michael xxmaj xxunk . \n",
       " \n",
       "  xxmaj welcome to xxmaj xxunk !"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(movie_reviews.valid.x)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3kRS3uIXPdWd"
   },
   "outputs": [],
   "source": [
    "def get_term_doc_matrix(label_list, vocab_len):\n",
    "    j_indices = []\n",
    "    indptr = []\n",
    "    values = []\n",
    "    indptr.append(0)\n",
    "\n",
    "    for i, doc in enumerate(label_list):\n",
    "        feature_counter = Counter(doc.data)\n",
    "        j_indices.extend(feature_counter.keys())\n",
    "        values.extend(feature_counter.values())\n",
    "        indptr.append(len(j_indices))\n",
    "        \n",
    "#     return (values, j_indices, indptr)\n",
    "\n",
    "    return scipy.sparse.csr_matrix((values, j_indices, indptr),\n",
    "                                   shape=(len(indptr) - 1, vocab_len),\n",
    "                                   dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "hfMHz-5_PdWf",
    "outputId": "023fbfc5-fbf9-4039-b116-712d7643e37c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 32.9 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "val_term_doc = get_term_doc_matrix(movie_reviews.valid.x, len(movie_reviews.vocab.itos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "7UuQEZZ7PdWg",
    "outputId": "c714ceee-71dd-45ae-a287-6f1d131e2367",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 226 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "trn_term_doc = get_term_doc_matrix(movie_reviews.train.x, len(movie_reviews.vocab.itos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "p6sZQtbnPdWk",
    "outputId": "442e7e94-5d6a-40f6-ed24-1afbcfac4fa8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800, 6008)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn_term_doc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "oEj3BOevPdWm",
    "outputId": "a533fc84-33a1-4087-d3a5-d810a9415401"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<800x10 sparse matrix of type '<class 'numpy.intc'>'\n",
       "\twith 10 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn_term_doc[:,-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "Yx3wzqS4PdWo",
    "outputId": "a499bfca-e5e6-4881-ef00-e6d7b1ecea54"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 6008)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_term_doc.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "E4hu_0UxPdWt"
   },
   "source": [
    "### Exploración adicional de datos:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6AyeNWdQPdWv"
   },
   "source": [
    "Podemos convertir nuestra matriz de una representación dispersa a una representación fila columna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "wkedZ-HAPdWw",
    "outputId": "8681385b-eeac-4359-fe29-60c7c00375f6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sollett']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_reviews.vocab.itos[-1:] #ultima palabra de la lista itos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 178
    },
    "colab_type": "code",
    "id": "ujWpIU3TPdWz",
    "outputId": "a6e04e02-3323-423a-e12a-782e05c76a22"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[32,  0,  1,  0, ...,  1,  0,  0, 10],\n",
       "        [ 9,  0,  1,  0, ...,  1,  0,  0,  7],\n",
       "        [ 6,  0,  1,  0, ...,  0,  0,  0, 12],\n",
       "        [78,  0,  1,  0, ...,  0,  0,  0, 44],\n",
       "        ...,\n",
       "        [ 8,  0,  1,  0, ...,  0,  0,  0,  8],\n",
       "        [43,  0,  1,  0, ...,  8,  1,  0, 25],\n",
       "        [ 7,  0,  1,  0, ...,  1,  0,  0,  9],\n",
       "        [19,  0,  1,  0, ...,  2,  0,  0,  5]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_term_doc.todense()[:10,:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "m_GqeZA3PdW0",
    "outputId": "f38b266e-ff60-4255-c83c-aa1002dc219a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sollett'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_reviews.vocab.itos[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 126
    },
    "colab_type": "code",
    "id": "KL6FlQhoPdW3",
    "outputId": "1dcdb5ab-841f-4082-f902-bca0d2888a35"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text xxbos i saw this movie once as a kid on the late - late show and fell in love with it . \n",
       " \n",
       "  xxmaj it took 30 + years , but i recently did find it on xxup dvd - it was n't cheap , either - in a xxunk that xxunk in war movies . xxmaj we watched it last night for the first time . xxmaj the audio was good , however it was grainy and had the trailers between xxunk . xxmaj even so , it was better than i remembered it . i was also impressed at how true it was to the play . \n",
       " \n",
       "  xxmaj the xxunk is around here xxunk . xxmaj if you 're xxunk in finding it , fire me a xxunk and i 'll see if i can get you the xxunk . xxunk"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review = movie_reviews.valid.x[1]\n",
    "review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "j-kBE-MOPdW6"
   },
   "source": [
    "**Ejercicio:**\n",
    "\n",
    "La palabra *late* aparece dos veces en esta crítica. Confirme que un valor de 2 es almanenado en la matriz de termino-documento.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ahpfPyi9PdW7"
   },
   "source": [
    "#### Respuesta (Programe la respuesta aquí):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PdvY4fudPdW8"
   },
   "outputs": [],
   "source": [
    "# Exercise: Confirm this\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "3XHVMcJXPdW9",
    "outputId": "a61b71ef-2ca8-4dd7-b370-aef01539197d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<200x6008 sparse matrix of type '<class 'numpy.int32'>'\n",
       "\twith 27848 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_term_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "7bXRT5BCPdW_",
    "outputId": "47959c97-8c3d-4a23-f40f-501ff739dd1c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x6008 sparse matrix of type '<class 'numpy.intc'>'\n",
       "\twith 81 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_term_doc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "H8ypiAgUPdXC",
    "outputId": "fa99eadd-13c1-40e2-a5a3-c33fa036b966"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "144"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_term_doc[1].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wo7m6aCFPdXE"
   },
   "source": [
    "La crítica tiene en total 81 tokens distintos con 144 en total."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "C12FqtW2PdXF",
    "outputId": "f7562745-f430-42dd-83c6-c95b1350d3f6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  2,  19, 248,  21, ...,   9,   0,  10,   0], dtype=int64)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WsraMgJ3PdXG"
   },
   "source": [
    "**Ejercicio 2:** Como convertir review.data en texto sin usar review.text?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XmmDz4rIPdXG"
   },
   "source": [
    "#### Respuesta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "6qxfqCL_PdXH",
    "outputId": "b363c6e2-24b2-4b73-9508-d41844c5543f"
   },
   "outputs": [],
   "source": [
    "# Exercise\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jryaSHD_PdXI"
   },
   "source": [
    "**Ejercicio 3**: Confirme que review tiene exactamente 81 tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mz-iFJ1JPdXO"
   },
   "source": [
    "#### Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "_Ze1xkKZPdXW",
    "outputId": "5f4e967b-0071-47da-9c45-c5dd469aa071"
   },
   "outputs": [],
   "source": [
    "# Escriba aquí la respuesta\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ¿Por qué stoi tiene más elementos que itos?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "colab_type": "code",
    "id": "8ltisByjPdXZ",
    "outputId": "02d9a632-a266-4215-de25-0c1a3badbec6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['state', 'street', 'impossible', 'clever', 'development']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_reviews.vocab.itos[1000:1005]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i8a4ZoapPdXa"
   },
   "source": [
    "`stoi` (string-to-int) is larger than `itos` (int-to-string)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "vFfrXpi3PdXc",
    "outputId": "4555ca3e-3227-4973-b5eb-44ea3b36092d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13154"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(movie_reviews.vocab.stoi) - len(movie_reviews.vocab.itos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rs3IQn0SPdXd"
   },
   "source": [
    "Hay muchas palabras que mapean unknown:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_RhOkiX4PdXd"
   },
   "outputs": [],
   "source": [
    "unk = []\n",
    "for word, num in movie_reviews.vocab.stoi.items():\n",
    "    if num == 0:\n",
    "        unk.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "iSa_dgiYPdXf",
    "outputId": "94568e51-3d9a-43f3-be5e-6df459682eaf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13155"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "OocF2t3pPdXi",
    "outputId": "af6bd987-0f86-4597-d48c-6d4b71c40f34",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['xxunk', 'bleeping', 'pert', 'ticky', 'schtick']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unk[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-UqSO08XPdXj"
   },
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2HwVqXTJPdXj"
   },
   "source": [
    "Definimos la relación logarítmica **log-count ratio** $r$ para cada palabra $f$:\n",
    "\n",
    "$r = \\log \\frac{\\text{ratio of feature $f$ in positive documents}}{\\text{ratio of feature $f$ in negative documents}}$\n",
    "\n",
    "Donde $f$ es el número de veces que un documento positivo/negativo tiene una característica dividida sobre el número de documentos positivos/negativos respectivamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "CuK2mb09PdXj",
    "outputId": "0d69ea02-8632-4858-89a8-183a6345693e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['negative', 'positive']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_reviews.y.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tY_TfyifPdXm"
   },
   "outputs": [],
   "source": [
    "x = trn_term_doc\n",
    "y = movie_reviews.train.y\n",
    "val_y = movie_reviews.valid.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OFAR1q6_PdXo"
   },
   "outputs": [],
   "source": [
    "positive = y.c2i['positive'] #obtiene clase a index para positivo 1\n",
    "negative = y.c2i['negative'] #obtain clase a index para negativo 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object ` x[y.items==positive].sum(0)` not found.\n"
     ]
    }
   ],
   "source": [
    "?? x[y.items==positive].sum(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MozW5wbrPdX0"
   },
   "outputs": [],
   "source": [
    "p1 = np.squeeze(np.asarray(x[y.items==positive].sum(0))) \n",
    "p0 = np.squeeze(np.asarray(x[y.items==negative].sum(0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "wURKFO6hPdXo",
    "outputId": "e8ad98cb-8d5b-4a84-9de2-f14525313a97"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6008, 6008)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(p1), len(p0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "iBG5z_cRPdXv",
    "outputId": "1e5394a6-d64b-495f-ead8-7461c7950691"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7154,    0,  417,    0, ...,    0,    3,    3,    3], dtype=int32)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.squeeze(np.asarray(x[y.items==negative].sum(0))) #conteos de una palabra totales en críticas negativas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "O9pW96n8PdXw",
    "outputId": "13b9c50c-ce9b-41a3-a123-ec21f56301bb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6471,    0,  383,    0, ...,    3,    0,    0,    0]], dtype=int32)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.asarray(x[y.items==positive].sum(0)) #retorna una lista de listas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "8BnK_DFYPdXz",
    "outputId": "04554f1c-569c-463f-f60a-2bf414479992"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6471,    0,  383,    0, ...,    3,    0,    0,    0], dtype=int32)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.squeeze(np.asarray(x[y.items==positive].sum(0))) #conteos de una palabra totales en críticas positivas, squeeze elimina esa dimensión adicional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NzvUWJbDPdX0"
   },
   "source": [
    "Para cada palabra en nuestro vocabulario estamos sumando en cuantas críticas positivas y en cuantas negativas están."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "bJARk2qgPdX3",
    "outputId": "105dd560-2200-44bc-8658-69632edc3054"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 6471,     0,   383,     0,     0, 10267,   674,    57,     0,  5260], dtype=int32)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p1[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4FIaeiG6PdX4"
   },
   "outputs": [],
   "source": [
    "v = movie_reviews.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "lq2jDnR6PdXt",
    "outputId": "fd5a85e0-8047-4247-dd4a-f400000f45ef"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'xxunk'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.itos[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'coaxes'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.itos[6004]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EvsgaTQIPdX5"
   },
   "source": [
    "### Usando los ratios para explorar datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ODJNlC-iPdX5"
   },
   "source": [
    "Se puede utilizar p0 y p1 para saber cuantas veces aparece una palabra dada en críticas positivas vs cuantas veces aparece en críticas negativas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "P5FEkBrePdX6"
   },
   "source": [
    "**Ejercicio**: Que tan a menudo aparece **loved** en críticas positivas vs. en críticas negativas... y **hated**?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8e2fq74PPdX6"
   },
   "source": [
    "#### Answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3e6jrp4JPdX9"
   },
   "outputs": [],
   "source": [
    "# Escriba aquí la relación para loved.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RhiAqaKePdX_"
   },
   "outputs": [],
   "source": [
    "# Escriba aquí la relación para hated.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jN_Jv8SEPdYA"
   },
   "source": [
    "#### Obtener reviews positivos para la palabra hated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IgiSjN-nPdYB"
   },
   "source": [
    "Es posible hacerlo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "gV4eGqkRPdYB",
    "outputId": "cddeff26-ce31-406e-aade-abcf6d2ad63f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1977"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.stoi['hated']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "qiCGCFY5PdYD",
    "outputId": "4096d553-e0bb-4c8d-cb79-14099d453923"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 15,  49, 304, 351, 393, 612, 695, 773])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.argwhere((x[:,1977] > 0))[:,0]\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "weuZtXs3PdYF",
    "outputId": "632d5084-40db-4acd-c179-6a0fd8e8df2a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1,   3,  10,  11, ..., 787, 789, 790, 797], dtype=int64)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = np.argwhere(y.items==positive)[:,0]\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "mv5okXWrPdYH",
    "outputId": "cb4e830a-c910-4731-cca2-11ea2827e06c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{393, 612, 695}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(a).intersection(set(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "id": "0PWEg674PdYH",
    "outputId": "d4e2534e-bf83-4cf6-90f7-e494ce66ce52"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"xxbos xxmaj xxunk , yeah this episode is extremely underrated . \\n \\n  xxmaj even though there is a xxup lot of bad writing and acting at parts . i think the good over wins the bad . \\n \\n  i love the xxunk parts and the big ' twist ' at the end . i absolutely love that scene when xxmaj michelle xxunk xxmaj tony . xxmaj it 's actually one of my favorite scenes of xxmaj season 1 . \\n \\n  xxmaj for some reason , people have always hated the xxmaj xxunk episodes , yet i have always liked them . xxmaj they 're not the best , in terms of writing . but the theme really does interest me , \\n \\n  i 'm gon na give it a xxup three star , but if the writing were a little more consistent i 'd give it xxup four .\""
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review = movie_reviews.train.x[695]\n",
    "review.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "56dXCq3GPdYJ"
   },
   "source": [
    "#### Obtener críticas negativas con la palabra \"loved\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4iXpKhe9PdYK"
   },
   "source": [
    "Miremos algunas críticas negativas con la palabra loved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "vfPoKG_2PdYK",
    "outputId": "5a638110-335a-489f-8c0f-c24b22e949d9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "535"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.stoi['loved']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "aSg1O3eUPdYL",
    "outputId": "ce8a4460-0632-4740-b458-17f3167fb63b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1,  15,  29,  69,  75,  79, 174, 185, 200, 205, 262, 296, 303, 333, 350, 351, 398, 407, 440, 489, 496, 528,\n",
       "       538, 600, 602, 605, 627, 642, 657, 660, 700, 712, 729, 735, 755, 767, 785])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.argwhere((x[:,535] > 0))[:,0]\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "B2I-ao7xPdYR",
    "outputId": "2ecc30d9-a56d-46d5-cfa8-52ee1643e68b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   2,   4,   5, ..., 795, 796, 798, 799], dtype=int64)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = np.argwhere(y.items==negative)[:,0]\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 499
    },
    "colab_type": "code",
    "id": "gv5kzkNIPdYV",
    "outputId": "9d7c2a70-4cf6-4e25-9a17-88ea7c0683b1",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{15, 200, 205, 303, 351, 398, 600, 605, 642, 700, 729, 767}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(a).intersection(set(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "id": "H2KfcqEaPdYX",
    "outputId": "2ddab430-adaa-4a89-cab9-271bf30257bc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"xxbos xxmaj this is n't one of xxmaj arbuckle 's or xxmaj keaton 's better films , that 's for sure . xxmaj fatty 's wife is tired of all his heavy drinking , so she takes him to a xxunk where a psychiatrist ( xxmaj keaton ) claims to have a guaranteed cure ! xxmaj well , once there , xxmaj arbuckle accidentally eats a xxunk and is taken to surgery . xxmaj then , he escapes and is chased about the place where he meets a cute girl who also wants to escape . xxmaj finally , despite xxunk chasing them about , they escape at which point it becomes apparent that the girl is crazy and xxmaj arbuckle is soon xxunk . xxmaj however , he xxunk and everything xxup after the surgery has all been a dream -- there was no sexy crazy girl and xxmaj dr. xxmaj keaton is n't as big an incompetent as he seemed in the dream . \\n \\n  a lack of humor is the biggest problem with the film . xxmaj sure , making fun of mentally ill people is pretty low , but in its day it was guaranteed laughs . i 'd laugh , too , if there was just something funny to xxunk to ! a lot of energy and that 's all . \\n \\n  xxup xxunk -- during one of the chase sequences , xxmaj fatty xxunk into a race for men over xxunk xxunk ( wow , what are the odds of that ? ) . xxmaj and , shortly after this , he backs into a post on which the number 5 was just xxunk painted . xxmaj as a result , the five is now on the back of xxmaj fatty 's shirt and he looks like a regular xxunk . xxup however , the number xxup should have appeared backwards on xxmaj fatty 's shirt but came out front - ways -- a mistake , as they should have realized the mirror image would have been a backwards 5 .\""
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review = movie_reviews.train.x[81]\n",
    "review.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Z1FPnVvcPdYY"
   },
   "source": [
    "## Aplicando Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_Xa-EZZmPdYY"
   },
   "outputs": [],
   "source": [
    "p1 = np.squeeze(np.asarray(x[y.items==positive].sum(0)))\n",
    "p0 = np.squeeze(np.asarray(x[y.items==negative].sum(0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CknYHzxZPdYa"
   },
   "outputs": [],
   "source": [
    "pr1 = (p1+1) / ((y.items==positive).sum() + 1)\n",
    "pr0 = (p0+1) / ((y.items==negative).sum() + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "JvklOpzPPdYb",
    "outputId": "5ee05c42-9fca-41fa-96bb-ee5139b9140a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.015487,  0.084839,  0.      ,  0.084839, ...,  1.471133, -1.301455, -1.301455, -1.301455])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = np.log(pr1/pr0); r "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bVK5SEqaPdYc"
   },
   "source": [
    "### Vocabulario asociado a críticas positivas o negativas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "llKPZ__XPdYc"
   },
   "outputs": [],
   "source": [
    "biggest = np.argpartition(r, -10)[-10:] #obtiene los 10 valores más grandes (críticas más positivas)\n",
    "smallest = np.argpartition(r, 10)[:10]  #obtiene los valores más pequeños (críticas más negativas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BPuYnvZFPdYe"
   },
   "source": [
    "Palabras más positivas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 196
    },
    "colab_type": "code",
    "id": "e8qdYLXZPdYf",
    "outputId": "e495e998-b7b3-43e6-b845-7b47550aaeab"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sport',\n",
       " 'davies',\n",
       " 'gilliam',\n",
       " 'fanfan',\n",
       " 'biko',\n",
       " 'felix',\n",
       " 'noir',\n",
       " 'jabba',\n",
       " 'astaire',\n",
       " 'jimmy']"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[v.itos[k] for k in biggest]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "H-JbWEITPdYg",
    "outputId": "8f957839-b8eb-441e-cf24-28a2507ec779"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "515"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(trn_term_doc[:,v.stoi['biko']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 305
    },
    "colab_type": "code",
    "id": "ZbnnmmUKPdYh",
    "outputId": "faabecf3-a5ce-44b8-c395-c510139a6ac9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text xxbos \" xxmaj the xxmaj true xxmaj story xxmaj of xxmaj the xxmaj friendship xxmaj that xxmaj shook xxmaj south xxmaj africa xxmaj and xxmaj xxunk xxmaj the xxmaj world . \" \n",
       " \n",
       "  xxmaj richard xxmaj attenborough , who directed \" a xxmaj bridge xxmaj too xxmaj far \" and \" xxmaj gandhi \" , wanted to bring the story of xxmaj steve xxmaj biko to life , and the journey and trouble that xxunk xxmaj donald xxmaj woods went through in order to get his story told . xxmaj the films uses xxmaj wood 's two books for it 's information and basis - \" xxmaj biko \" and \" xxmaj asking for xxmaj trouble \" . \n",
       " \n",
       "  xxmaj the film takes place in the late 1970 's , in xxmaj south xxmaj africa . xxmaj south xxmaj africa is in the grip of the terrible apartheid , which keeps the blacks separated from the whites and xxunk the whites as the superior race . xxmaj the blacks are forced to live in xxunk on the xxunk of the cities and xxunk , and they come under frequent xxunk by the police and the army . xxmaj we are shown a dawn xxunk on a xxunk , as xxunk and armed police force their way through the camp beating and even killing the inhabitants . xxmaj then we are introduced to xxmaj donald xxmaj woods ( xxmaj kevin xxmaj kline ) , who is the editor of a popular newspaper . xxmaj after xxunk a negative story about black xxunk xxmaj steve xxmaj biko ( xxmaj denzel xxmaj washington ) , xxmaj woods goes to meet with him . xxmaj the two are xxunk of each other at first , but they soon become good friends and xxmaj biko shows the horrors of the apartheid system from a black persons point of view to xxmaj woods . xxmaj this xxunk xxmaj woods to speak out against what 's happening around him , and makes him desperate to bring xxmaj steve xxmaj biko 's story out of the xxunk of the white man 's xxmaj south xxmaj africa and to the world . xxmaj soon , xxmaj steve xxmaj biko is arrested and is killed in prison . xxmaj now xxmaj woods and his family are daring to escape from xxmaj south xxmaj africa to xxmaj england , where xxmaj woods can xxunk his book about xxmaj steve xxmaj biko and the apartheid . \n",
       " \n",
       "  xxmaj when i first heard of \" xxmaj cry xxmaj freedom \" , i was under the impression that it was a movie completely dedicated to the life of xxmaj steve xxmaj biko . i had never actually heard of xxmaj steve xxmaj biko before i seen this film , as the events in this film were really before my time . xxmaj but it 's more about the story of xxmaj donald xxmaj woods and his journey across the border into xxmaj xxunk as he tried to xxunk the xxmaj south xxmaj african xxunk . xxmaj woods was put on a five year type house xxunk after xxmaj steve xxmaj biko was killed . xxmaj so in order to xxunk his xxunk on xxmaj steve xxmaj biko , he had to escape . xxmaj because the xxunk would be considered xxunk in xxmaj south xxmaj africa and that could have resulted in xxmaj woods meeting a fate similar to that of xxmaj biko 's . xxmaj the real xxmaj donald xxmaj woods and his wife acted as xxunk to this film . \n",
       " \n",
       "  xxmaj denzel xxmaj washington is only in the film for the first hour , and i was disappointed with that as i was expecting to see him for the entire movie . xxmaj but he was amazing as xxmaj steve xxmaj biko , and captured his personality from what i 've read really well and his accent sounded perfect . xxmaj his performance earned him an xxmaj oscar nomination for xxmaj best xxmaj supporting xxmaj actor . xxmaj kevin xxmaj kline delivers a excellent and thought - xxunk performance as xxmaj donald xxmaj woods , and xxmaj penelope xxmaj xxunk is excellent as his wife xxmaj xxunk . \n",
       " \n",
       "  xxmaj filming took place in xxmaj xxunk , as needless to say problems xxunk when they tried to film it in xxmaj south xxmaj africa . xxmaj while in xxmaj south xxmaj africa , the xxmaj south xxmaj african xxunk followed the film crew everywhere , so they got the bad xxunk and they pulled out and went to xxunk xxmaj xxunk instead . xxmaj despite everything , and the fact that the apartheid did n't end ' xxunk seven years later , \" xxmaj cry xxmaj freedom \" was n't xxunk in xxmaj south xxmaj africa . xxmaj but xxunk showing the movie received bomb threats . \n",
       " \n",
       "  xxmaj richard xxmaj attenborough brings the horrors of the apartheid to the screen with extreme force and determination . xxmaj he does n't hold back at the end of the movie when showing what was supposed to be a xxunk xxunk by students in a xxunk , turns into a massacre when police open fire on them . xxmaj the film ends with the names of all the anti - apartheid xxunk who died in prison , and the explanations for their deaths . xxmaj many had \" xxmaj no xxmaj explanation \" . xxmaj quite a few were \" xxmaj xxunk \" , which is hard to believe , and many more either fell from the top of the xxunk or were \" xxmaj suicide from xxmaj hanging \" . xxmaj no one will ever know what really happened to them , but i think it 's fair to say that none of these men died at their own hands , but at the hands of others ; or to be more xxunk , at the hands of the police . \n",
       " \n",
       "  \" xxmaj cry xxmaj freedom \" is a must - see movie for it 's portrayal and story of xxmaj steve xxmaj biko . xxmaj it 's also a xxunk and xxunk portrayal of a beautiful land divided and in the xxunk grips of racial xxunk and violence ."
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_reviews.train.x[515]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZE311M87PdYj"
   },
   "source": [
    "Most negative words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 196
    },
    "colab_type": "code",
    "id": "dthW8926PdYj",
    "outputId": "558b2282-7106-4001-bda3-deca725b0413",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['worst',\n",
       " 'crap',\n",
       " 'crater',\n",
       " 'porn',\n",
       " 'disappointment',\n",
       " 'dog',\n",
       " 'vargas',\n",
       " 'naschy',\n",
       " 'fuqua',\n",
       " 'soderbergh']"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[v.itos[k] for k in smallest]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "841yMUH7PdYk",
    "outputId": "626a20cb-4557-4919-8447-1e51dcf5e8dd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "434"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(trn_term_doc[:,v.stoi['soderbergh']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 877
    },
    "colab_type": "code",
    "id": "UTFksCNNPdYk",
    "outputId": "3c2d5bfe-6229-4f3d-f1d0-0a4032f799e9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text xxbos xxmaj now that xxmaj che(2008 ) has finished its relatively short xxmaj australian cinema run ( extremely limited xxunk screen in xxmaj xxunk , after xxunk ) , i can xxunk join both xxunk of \" xxmaj at xxmaj the xxmaj movies \" in taking xxmaj steven xxmaj soderbergh to task . \n",
       " \n",
       "  xxmaj it 's usually satisfying to watch a film director change his style / subject , but xxmaj soderbergh 's most recent stinker , xxmaj the xxmaj girlfriend xxmaj xxunk ) , was also missing a story , so narrative ( and editing ? ) seem to suddenly be xxmaj soderbergh 's main challenge . xxmaj strange , after xxunk years in the business . xxmaj he was probably never much good at narrative , just xxunk it well inside \" edgy \" projects . \n",
       " \n",
       "  xxmaj none of this excuses him this present , almost diabolical failure . xxmaj as xxmaj david xxmaj xxunk xxunk , \" two parts of xxmaj che do n't ( even ) make a whole \" . \n",
       " \n",
       "  xxmaj epic xxunk in name only , xxmaj che(2008 ) barely qualifies as a feature film ! xxmaj it certainly has no legs , xxunk as except for its xxunk ultimate resolution forced upon it by history , xxmaj soderbergh 's xxunk - long xxunk just goes nowhere . \n",
       " \n",
       "  xxmaj even xxmaj margaret xxmaj xxunk , the more xxunk of xxmaj australia 's xxmaj at xxmaj the xxmaj movies duo , noted about xxmaj soderbergh 's xxunk waste of ( xxup xxunk digital xxunk ) : \" you 're in the woods ... xxunk in the woods ... xxunk in the woods ... \" . i too am surprised xxmaj soderbergh did n't give us another xxunk of xxup that somewhere between his xxunk two xxmaj parts , because he still left out massive xxunk of xxmaj che 's \" xxunk \" life ! \n",
       " \n",
       "  xxmaj for a xxunk of an important but infamous historical figure , xxmaj soderbergh xxunk xxunk , if not deliberately insults , his audiences by \n",
       " \n",
       "  1 . never providing most of xxmaj che 's story ; \n",
       " \n",
       "  2 . xxunk xxunk film xxunk with mere xxunk xxunk ; \n",
       " \n",
       "  3 . xxunk both true xxunk and a narrative of events ; \n",
       " \n",
       "  4 . barely developing an idea , or a character ; \n",
       " \n",
       "  5 . remaining xxunk episodic ; \n",
       " \n",
       "  6 . xxunk proper context for scenes --- whatever we do get is xxunk in xxunk xxunk ; \n",
       " \n",
       "  7 . xxunk xxunk all audiences ( even xxmaj spanish - xxunk will be confused by the xxunk xxunk in xxmaj english ) ; and \n",
       " \n",
       "  8 . xxunk xxunk his main subject into one dimension . xxmaj why , at xxup this late stage ? xxmaj the t - shirt franchise has been a success ! \n",
       " \n",
       "  xxmaj our sense of xxunk is surely due to xxmaj peter xxmaj xxunk and xxmaj benjamin xxunk xxmaj xxunk xxunk their screenplay solely on xxmaj xxunk 's memoirs . xxmaj so , like a poor student who has read only xxup one of his xxunk xxunk for his xxunk , xxmaj soderbergh 's product is xxunk limited in perspective . \n",
       " \n",
       "  xxmaj the audience is held captive within the same xxunk knowledge , scenery and circumstances of the \" revolutionaries \" , but that does n't xxunk our sympathy . xxmaj instead , it xxunk on us that \" xxmaj ah , xxmaj soderbergh 's trying to xxunk his audiences the same as the xxmaj latino peasants were at the time \" . xxmaj but these are the xxup same illiterate xxmaj latino peasants who xxunk out the good doctor to his enemies . xxmaj why does xxmaj soderbergh feel the need to xxunk us with them , and keep us equally mentally captive ? xxmaj such audience xxunk must have a purpose . \n",
       " \n",
       "  xxmaj part2 is more xxunk than xxmaj part1 , but it 's literally mind - numbing with its repetitive bush - bashing , misery of xxunk , and lack of variety or character xxunk . deltoro 's xxmaj che has no opportunity to grow as a person while he struggles to xxunk his own ill - xxunk troops . xxmaj the only xxunk is the humour as xxmaj che deals with his sometimes deeply ignorant \" revolutionaries \" , some of whom xxunk lack self - control around local peasants or food . xxmaj we certainly get no insight into what caused the conditions , nor any xxunk xxunk of their xxunk xxunk , such as it was . \n",
       " \n",
       "  xxmaj part2 's xxunk xxunk remains xxunk episodic : again , nothing is telegraphed or xxunk . xxmaj thus even the scenes with xxmaj xxunk xxmaj xxunk ( xxmaj xxunk xxmaj xxunk ) are unexpected and disconcerting . xxmaj any xxunk events are portrayed xxunk and xxmaj latino - xxunk , with xxmaj part1 's interviews xxunk by time - xxunk xxunk between the corrupt xxmaj xxunk president ( xxmaj xxunk de xxmaj xxunk ) and xxup us xxmaj government xxunk promising xxup cia xxunk ( ! ) . \n",
       " \n",
       "  xxmaj the rest of xxmaj part2 's \" woods \" and day - for - night blue xxunk just xxunk the audience until they 're xxunk the xxunk . \n",
       " \n",
       "  xxmaj perhaps deltoro felt too xxunk the frustration of many non - xxmaj american xxmaj latinos about never getting a truthful , xxunk history of xxmaj che 's xxunk within their own countries . xxmaj when foreign xxunk still wo n't deliver a free press to their people -- for whatever reason -- then one can see how a popular xxmaj american indie producer might set out to xxunk the not - so - well - read ( \" i may not be able to read or write , but i 'm xxup not xxunk . xxmaj the xxmaj inspector xxmaj xxunk ) ) out to their own local xxunk . xxmaj the film 's obvious xxunk and gross over - xxunk hint very strongly that it 's aiming only at the xxunk of the less - informed xxup who xxup still xxup speak xxup little xxmaj english . xxmaj if they did , they 'd have read xxunk on the subject already , and xxunk the relevant social issues amongst themselves -- learning the lessons of history as they should . \n",
       " \n",
       "  xxmaj such insights are precisely what societies still need -- and not just the remaining illiterate xxmaj latinos of xxmaj central and xxmaj south xxmaj america -- yet it 's what xxmaj che(2008 ) xxunk fails to deliver . xxmaj soderbergh xxunk his lead because he 's weak on narrative . i am xxunk why xxmaj xxunk deltoro deliberately chose xxmaj soderbergh for this project if he knew this . xxmaj it 's been xxunk , xxunk about xxmaj xxunk was xxunk wanted : it 's what i went to see this film for , but the director xxunk robs us of that . \n",
       " \n",
       "  xxmaj david xxmaj xxunk , writing in xxmaj the xxmaj australian ( xxunk ) observed that while xxmaj part1 was \" uneven \" , xxmaj part2 actually \" goes rapidly downhill \" from there , \" xxunk xxmaj che 's final xxunk in xxmaj xxunk in xxunk detail \" , which \" ... feels almost unbearably slow and turgid \" . \n",
       " \n",
       "  xxmaj che : xxmaj the xxmaj xxunk aka xxmaj part2 is certainly no xxunk for xxmaj xxunk , painting it a picture of misery and xxunk . xxmaj the entire second half is only xxunk by the aforementioned humour , and the dramatic -- yet tragic -- capture and execution of the film 's subject . \n",
       " \n",
       "  xxmaj the rest of this xxunk cinema xxunk is just confusing , irritating misery -- xxunk , for a xxmaj soderbergh film , to be avoided at all costs . xxmaj it is bound to break the hearts of all who know even just a xxunk about the xxunk / 10 )"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_reviews.train.x[434]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "OHWfQNDtPdYn",
    "outputId": "168955fa-25b1-41c2-8d4b-6fff73c90fbe"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<800x1 sparse matrix of type '<class 'numpy.intc'>'\n",
       "\twith 1 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn_term_doc[:,v.stoi['soderbergh']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 196
    },
    "colab_type": "code",
    "id": "kHP0glcoPdYn",
    "outputId": "3a715d07-6290-4c3b-e3bf-14d8c24eeeb7",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['worst',\n",
       " 'crap',\n",
       " 'crater',\n",
       " 'porn',\n",
       " 'disappointment',\n",
       " 'dog',\n",
       " 'vargas',\n",
       " 'naschy',\n",
       " 'fuqua',\n",
       " 'soderbergh']"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[v.itos[k] for k in smallest]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mJ-a92S9PdYo"
   },
   "source": [
    "### Naive Bayes: continuación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "SWqB4wanPdYq",
    "outputId": "b59346e5-f6e5-49b3-9517-d28965b42dd8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.47875, 0.52125)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(y.items==positive).mean(), (y.items==negative).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tX8CQPOGPdYq"
   },
   "outputs": [],
   "source": [
    "b = np.log((y.items==positive).mean() / (y.items==negative).mean()) #normaliza para encontrar la razón logarítmica del número promedio de críticas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xhV7h8qiPdYr"
   },
   "outputs": [],
   "source": [
    "preds = (val_term_doc @ r + b) > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "Cst7ZuJ6PdYt",
    "outputId": "2fe7319d-c488-4549-b7fc-55ce9272d269"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.645"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(preds == val_y.items).mean() #promedio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HsHXqguzPdYu"
   },
   "source": [
    "## Pasando al dataset completo "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1LZZQOHfPdYu"
   },
   "source": [
    "Dado que funcionó con el data set de ejemplo pasamos a probar el dataset completo:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dDwqDu2KPdYv"
   },
   "source": [
    "### Download data and process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 142
    },
    "colab_type": "code",
    "id": "i4GHDXYsPdYv",
    "outputId": "bfa627de-99b8-4729-cecb-cce0ccb72a01"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WindowsPath('C:/Users/Arles/.fastai/data/imdb/imdb.vocab'),\n",
       " WindowsPath('C:/Users/Arles/.fastai/data/imdb/imdb_textlist_class'),\n",
       " WindowsPath('C:/Users/Arles/.fastai/data/imdb/lm_databunch'),\n",
       " WindowsPath('C:/Users/Arles/.fastai/data/imdb/models'),\n",
       " WindowsPath('C:/Users/Arles/.fastai/data/imdb/README'),\n",
       " WindowsPath('C:/Users/Arles/.fastai/data/imdb/test'),\n",
       " WindowsPath('C:/Users/Arles/.fastai/data/imdb/tmp_clas'),\n",
       " WindowsPath('C:/Users/Arles/.fastai/data/imdb/tmp_lm'),\n",
       " WindowsPath('C:/Users/Arles/.fastai/data/imdb/train'),\n",
       " WindowsPath('C:/Users/Arles/.fastai/data/imdb/unsup')]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = untar_data(URLs.IMDB)\n",
    "path.ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "id": "vmrx6vl2PdYx",
    "outputId": "76b23855-d570-4e22-b728-1a68ea80743e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WindowsPath('C:/Users/Arles/.fastai/data/imdb/train/labeledBow.feat'),\n",
       " WindowsPath('C:/Users/Arles/.fastai/data/imdb/train/neg'),\n",
       " WindowsPath('C:/Users/Arles/.fastai/data/imdb/train/pos'),\n",
       " WindowsPath('C:/Users/Arles/.fastai/data/imdb/train/unsupBow.feat')]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(path/'train').ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BrqS-CK3PdYy"
   },
   "outputs": [],
   "source": [
    "reviews_full = (TextList.from_folder(path)\n",
    "             #grab all the text files in path\n",
    "             .split_by_folder(valid='test')\n",
    "             #split by train and valid folder (that only keeps 'train' and 'test' so no need to filter)\n",
    "             .label_from_folder(classes=['neg', 'pos']))\n",
    "             #label them all with their folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "Io-pSJGDPdYy",
    "outputId": "10cec762-85b9-4001-e70a-1a6fad5c855b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 25000)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(reviews_full.train), len(reviews_full.valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yTUlCp_dPdY0"
   },
   "source": [
    "We will store the vocab in a variable `v` since we will be using it frequently:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "62KrTSguPdY0"
   },
   "outputs": [],
   "source": [
    "v = reviews_full.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 196
    },
    "colab_type": "code",
    "id": "th0kV-r_PdY2",
    "outputId": "c633dbb5-be1a-470d-a68c-3c6a7687e9c7",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bad',\n",
       " 'people',\n",
       " 'will',\n",
       " 'other',\n",
       " 'also',\n",
       " 'into',\n",
       " 'first',\n",
       " 'because',\n",
       " 'great',\n",
       " 'how']"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.itos[100:110]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "LWrCsLesPdY3",
    "outputId": "638c4215-b4d5-4644-9b1e-b428f6c5de5f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 5.15 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "val_term_doc = get_term_doc_matrix(reviews_full.valid.x, len(reviews_full.vocab.itos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "Ak9Iwk6xPdY5",
    "outputId": "842b27ad-4b5e-4328-cc56-0c1477c98cea",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 5.51 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "trn_term_doc = get_term_doc_matrix(reviews_full.train.x, len(reviews_full.vocab.itos))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tps38zyDPdY6"
   },
   "source": [
    "### Guardar y cargar la matriz de término-documento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HqsjZ1TYPdY6"
   },
   "source": [
    "Como el proceso es lento es una muy buena idea guardar la matriz y después cargarla."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UhKipym7PdY7"
   },
   "outputs": [],
   "source": [
    "scipy.sparse.save_npz(\"trn_term_doc.npz\", trn_term_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5JPkaYcpPdY7"
   },
   "outputs": [],
   "source": [
    "scipy.sparse.save_npz(\"val_term_doc.npz\", val_term_doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yij9yAuoPdY9"
   },
   "source": [
    "Cuando se guarde debe añadirse a git.ignore en caso de manejar git."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hs3Yq0mFPdY9"
   },
   "source": [
    "Así se cargan los datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WoLZCeWMPdY-"
   },
   "outputs": [],
   "source": [
    "trn_term_doc = scipy.sparse.load_npz(\"trn_term_doc.npz\")\n",
    "val_term_doc = scipy.sparse.load_npz(\"val_term_doc.npz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZmnUD08rPdY_"
   },
   "source": [
    "### Naive Bayes on full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MunlK5kePdY_"
   },
   "outputs": [],
   "source": [
    "x=trn_term_doc\n",
    "y=reviews_full.train.y\n",
    "\n",
    "val_y = reviews_full.valid.y.items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "zYIqh0SVPdZB",
    "outputId": "cfe56dc9-651d-453c-9b47-86ca922c631c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<25000x38456 sparse matrix of type '<class 'numpy.int32'>'\n",
       "\twith 3716265 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jzy7wuEXPdZC"
   },
   "outputs": [],
   "source": [
    "positive = y.c2i['pos']\n",
    "negative = y.c2i['neg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PDkxT_6tPdZD"
   },
   "outputs": [],
   "source": [
    "p0 = np.squeeze(np.asarray(x[y.items==negative].sum(0)))\n",
    "p1 = np.squeeze(np.asarray(x[y.items==positive].sum(0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "AAeyHZFXPdZE",
    "outputId": "779b14e2-6c65-44c4-9025-86da995b1c8d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 28450,      0,  12500,      0,      0, 342619,  20464,   1338,      7, 173122, 138000, 143763,  89570,  83404,\n",
       "        76828,  66715,  58510,  47896,  50177,  40451], dtype=int32)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p1[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Szcj4ktjPdZF"
   },
   "source": [
    "### Exploración de datos: razones de una palabra en críticas positivas y negativas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s-htKLu_PdZG"
   },
   "source": [
    "Es posible obtener la razón entre el número de veces una palabra dada aparece en críticas negativas en positivas. Razones ( > 1) significan que la palabra indica un review negativo y valores (< 1) indican un review positivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1ptNsH4KPdZG"
   },
   "outputs": [],
   "source": [
    "def neg_pos_given_word(word):\n",
    "    print(p0[v.stoi[word]]/p1[v.stoi[word]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "Z3l7Up3qPdZH",
    "outputId": "31aa5b7e-72b9-4484-f49b-7ec5a4b982b5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.051546391752577\n"
     ]
    }
   ],
   "source": [
    "neg_pos_given_word('hated')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "WEKMZfVyPdZL",
    "outputId": "cc8bcbc3-dc21-4926-9c12-7ef583c3bc1f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6424702058504875\n"
     ]
    }
   ],
   "source": [
    "neg_pos_given_word('liked')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "9e03wupuPdZO",
    "outputId": "7f86a16c-0779-4e84-f157-e9dd647b270c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3139963167587477\n"
     ]
    }
   ],
   "source": [
    "neg_pos_given_word('loved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "aGpr8HG_PdZP",
    "outputId": "c61f819f-49c1-4f3e-f49c-42385a8bd9da"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.48538961038961037\n"
     ]
    }
   ],
   "source": [
    "neg_pos_given_word('best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "c66OgtypPdZQ",
    "outputId": "b60419e2-b7a5-456e-8516-eb5630da0178"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.837301587301587\n"
     ]
    }
   ],
   "source": [
    "neg_pos_given_word('worst')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C4_xvHyBPdZR"
   },
   "outputs": [],
   "source": [
    "pr1 = (p1+1) / ((y.items==positive).sum() + 1)\n",
    "pr0 = (p0+1) / ((y.items==negative).sum() + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9YVS4zodPdZR"
   },
   "outputs": [],
   "source": [
    "r = np.log(pr1/pr0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "c6y5QXQ_PdZT",
    "outputId": "c6385cab-dae5-4fc4-8b47-44d19faf3c0a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.7133498878774648"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r[v.stoi['hated']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "0lM1Wfa4PdZU",
    "outputId": "583c9f60-8bd1-4d42-a081-e5a35dd700e1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1563661500586044"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r[v.stoi['loved']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "2jl98L89PdZV",
    "outputId": "d13a9a8e-b257-4853-d33e-3737d5a7730e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-2.2826243504315076"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r[v.stoi['worst']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "ASFiPCKKPdZX",
    "outputId": "07e63a9f-8e1b-4075-f858-1ac36aad067a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7225576052173609"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r[v.stoi['best']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "U-ZhX_qDPdZY"
   },
   "source": [
    "### Naive Bayes sobre el data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vyfVyM1MPdZZ"
   },
   "outputs": [],
   "source": [
    "negative = y.c2i['neg']\n",
    "p0 = np.squeeze(np.asarray(x[y.items==negative].sum(0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xnahb3rvPdZa"
   },
   "source": [
    "Como tenemos un número igual de críticas positivas y negativas b es 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2jy1a6q0PdZa"
   },
   "outputs": [],
   "source": [
    "pr1 = (p1+1) / ((y.items==positive).sum() + 1)\n",
    "pr0 = (p0+1) / ((y.items==negative).sum() + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "YRRFyessPdZm",
    "outputId": "0408bd17-7dad-45fb-8b6b-039ceeac0915"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = np.log((y.items==positive).mean() / (y.items==negative).mean()); b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7vHmLqviPdZn"
   },
   "outputs": [],
   "source": [
    "preds = (val_term_doc @ r + b) > 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WL8MquxLPdZn"
   },
   "source": [
    "Nuestro accuracy es de 80% para el dataset completo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "PJEt3NvfPdZn",
    "outputId": "258e1063-1621-4b63-c05f-2ea25953533e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8084"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(preds == val_y).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ELJnSqyfPdZp"
   },
   "source": [
    "### Naive Bayes Binarizado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Mvjc17wgPdZp"
   },
   "source": [
    "Maybe it only matters whether a word is in the review or not (not the frequency of the word):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2qhyBsyRPdZp"
   },
   "outputs": [],
   "source": [
    "x=trn_term_doc.sign()\n",
    "y=reviews_full.train.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 178
    },
    "colab_type": "code",
    "id": "9sv_K1L3PdZr",
    "outputId": "f627c9e0-ef0d-41fd-e47c-f68fe95a8129"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[1, 0, 1, 0, ..., 1, 0, 0, 1],\n",
       "        [1, 0, 1, 0, ..., 1, 0, 0, 1],\n",
       "        [1, 0, 1, 0, ..., 0, 0, 0, 1],\n",
       "        [0, 0, 1, 0, ..., 0, 1, 0, 1],\n",
       "        ...,\n",
       "        [1, 0, 1, 0, ..., 0, 0, 0, 1],\n",
       "        [0, 0, 1, 0, ..., 1, 0, 0, 1],\n",
       "        [0, 0, 1, 0, ..., 0, 0, 0, 1],\n",
       "        [0, 0, 1, 0, ..., 1, 0, 0, 1]])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.todense()[:10,:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_BCBI4QAPdZs"
   },
   "outputs": [],
   "source": [
    "negative = y.c2i['neg']\n",
    "positive = y.c2i['pos']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ynnOadboPdZt"
   },
   "outputs": [],
   "source": [
    "p1 = np.squeeze(np.asarray(x[y.items==positive].sum(0)))\n",
    "p0 = np.squeeze(np.asarray(x[y.items==negative].sum(0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j7mUU8owPdZu"
   },
   "outputs": [],
   "source": [
    "pr1 = (p1+1) / ((y.items==positive).sum() + 1)\n",
    "pr0 = (p0+1) / ((y.items==negative).sum() + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sPUgS5nePdZw"
   },
   "outputs": [],
   "source": [
    "r = np.log(pr1/pr0)\n",
    "b = np.log((y.items==positive).mean() / (y.items==negative).mean())\n",
    "\n",
    "preds = (val_term_doc.sign() @ r + b) > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "G-0GtMHaPdZx",
    "outputId": "8583f1c9-246f-4e09-913e-8c671cc118d3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.82924"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(preds==val_y).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Wty8PKyZPdZy"
   },
   "source": [
    "## Regresión logística"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ATeIXb77PdZy"
   },
   "source": [
    "Es posible ejecutar un modelo de regresión logística cuando las características son unigramas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "62q7W-MkPdZy"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "3tSbJmPVPdZ1",
    "outputId": "8310607a-bed8-4d8c-f908-1f5df89b6d92"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7704"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = LogisticRegression(C=0.1, dual=True)\n",
    "m.fit(x, y.items.astype(int))\n",
    "preds = m.predict(val_term_doc)\n",
    "(preds==val_y).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ym7glJfLPdZ1"
   },
   "source": [
    "Y la versión binaria:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "Xyyd1tO7PdZ2",
    "outputId": "1aeb09dc-1623-45d6-9055-63323ae25cc3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.88536"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = LogisticRegression(C=0.1, dual=True)\n",
    "m.fit(trn_term_doc.sign(), y.items.astype(int))\n",
    "preds = m.predict(val_term_doc.sign())\n",
    "(preds==val_y).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1kkVTtl-PdZ3"
   },
   "source": [
    "# Trigramas con Naive Bayes "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ez3ghvOOPdZ4"
   },
   "source": [
    "A continuación se muestra un modelo de regresión logística con Naive Bayes desarrollado [aquí](https://www.aclweb.org/anthology/P12-2018). Para cada documento computamos atributos binarizados como se describió en la parte superior pero esta vez utilizando bigramas y trigramas. Cada característica es un log-count ratio. Un modelo de regresión logística es entrenado para predecir sentimientos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "V906-ANbPdZ4"
   },
   "source": [
    "### n-gramas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "efgKz5bmPdZ5"
   },
   "source": [
    "Un n-grama es una secuencia continua de ítmes (donde un item es una letra, una sílaba o una palabra). Un 1-grama es un unigrama, un 2-gram es un bigrama y un 3-gram es un trigrama\n",
    "\n",
    "En este caso son secuencias contínuas de palabras como: \"the dog\", \"said that\" \"can't you\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P7ukEh1gPdZ5"
   },
   "outputs": [],
   "source": [
    "path = untar_data(URLs.IMDB_SAMPLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UfcKN8d7PdZ5"
   },
   "outputs": [],
   "source": [
    "movie_reviews = (TextList.from_csv(path, 'texts.csv', cols='text')\n",
    "                .split_from_df(col=2)\n",
    "                .label_from_df(cols=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "u6p0rbG9PdZ6"
   },
   "outputs": [],
   "source": [
    "v = movie_reviews.vocab.itos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p-Z_nQrCPdZ7"
   },
   "outputs": [],
   "source": [
    "vocab_len = len(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jxGGAJZ9PdZ8"
   },
   "source": [
    "## Nuestros datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yRAsoNyDPdZ8"
   },
   "source": [
    "### Creación de la matriz de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eaVAmKA9PdZ8"
   },
   "outputs": [],
   "source": [
    "min_n=1\n",
    "max_n=3\n",
    "\n",
    "j_indices = []\n",
    "indptr = []\n",
    "values = []\n",
    "indptr.append(0)\n",
    "num_tokens = vocab_len\n",
    "\n",
    "itongram = dict()\n",
    "ngramtoi = dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_CcvQyNlPdZ-"
   },
   "source": [
    "Iteramos sobre todas las secuencias de palabras para crear los n-gramas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bD62CvxLPdZ_"
   },
   "outputs": [],
   "source": [
    "for i, doc in enumerate(movie_reviews.train.x):\n",
    "    feature_counter = Counter(doc.data)\n",
    "    j_indices.extend(feature_counter.keys())\n",
    "    values.extend(feature_counter.values())\n",
    "    this_doc_ngrams = list()\n",
    "\n",
    "    m = 0\n",
    "    for n in range(min_n, max_n + 1):\n",
    "        for k in range(vocab_len - n + 1):\n",
    "            ngram = doc.data[k: k + n]\n",
    "            if str(ngram) not in ngramtoi:\n",
    "                if len(ngram)==1:\n",
    "                    num = ngram[0]\n",
    "                    ngramtoi[str(ngram)] = num\n",
    "                    itongram[num] = ngram\n",
    "                else:\n",
    "                    ngramtoi[str(ngram)] = num_tokens\n",
    "                    itongram[num_tokens] = ngram\n",
    "                    num_tokens += 1\n",
    "            this_doc_ngrams.append(ngramtoi[str(ngram)])\n",
    "            m += 1\n",
    "\n",
    "    ngram_counter = Counter(this_doc_ngrams)\n",
    "    j_indices.extend(ngram_counter.keys())\n",
    "    values.extend(ngram_counter.values())\n",
    "    indptr.append(len(j_indices))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qcyK6NM9PdaB"
   },
   "source": [
    "Es útil emplear diccionarios para convertir entre índices y strings (en este caso n-gramas). Tenemos dos estructuras generadas del código anterios `itongram` (index to n-gram) y `ngramtoi` (n-gram to index)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n5XVRpc7PdaB"
   },
   "outputs": [],
   "source": [
    "train_ngram_doc_matrix = scipy.sparse.csr_matrix((values, j_indices, indptr),\n",
    "                                   shape=(len(indptr) - 1, len(ngramtoi)),\n",
    "                                   dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "J_PE7PbaPdaC",
    "outputId": "a05e055a-08f0-47de-8634-318371255495"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<800x260374 sparse matrix of type '<class 'numpy.int32'>'\n",
       "\twith 678885 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ngram_doc_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8es2mtlxPdaD"
   },
   "source": [
    "### Revisando los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "4EByYDcVPdaD",
    "outputId": "a1edf9f1-3fe1-4373-ea41-f827da391553"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(260374, 260374)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ngramtoi), len(itongram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "8XVidpM0PdaE",
    "outputId": "7750648d-dfd2-4a73-989d-1160e1f63e2d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 15,   9, 710], dtype=int64)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itongram[20005]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "vc_kfNVpPdaF",
    "outputId": "1f8aac2a-87c7-44bd-911a-c7635bdb6ef4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20005"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngramtoi[str(np.array([15,   9,  710]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "hZ073newPdaG",
    "outputId": "ab3828e6-f41b-4e3f-f9d6-8d32ef570468"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1140,   33], dtype=int64)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itongram[100000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "SQSROzLQPdaH",
    "outputId": "a4cac600-8404-4322-b91b-d049300e71fc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('to', 'the', 'leads')"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v[15], v[9], v[710]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "RqwKH9OVPdaI",
    "outputId": "054b574f-e3eb-434d-82bc-71b3cb473623"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5430,   10], dtype=int64)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itongram[100010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "GDlDxIxAPdaI",
    "outputId": "6ef386b6-caa6-4de4-b36f-dcdc15e900fa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('photographer', '.')"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v[5430], v[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "IJl_DSBUPdaK",
    "outputId": "a989da44-fb51-43e7-9703-6da6ca5206c5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 85, 191,  64], dtype=int64)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itongram[6116]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "dfrvMLRaPdaL",
    "outputId": "e620f3d4-e20f-4f58-bafc-3f19abef3124"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('even', 'look', 'her')"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v[85], v[191], v[64]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "8MBRcIxdPdaO",
    "outputId": "3176ed28-e4f0-4dee-fc73-622011ed7230"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2594,   14, 2618], dtype=int64)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itongram[80000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "3qTtnWcZPdaO",
    "outputId": "6eab5fd6-e941-40bc-e83a-8c784058b2d7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('loss', 'of', 'sleep')"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v[2594], v[14], v[2618]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NMjzEBcJPdaP"
   },
   "source": [
    "### Cración de matriz de validación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JJun23cxPdaQ"
   },
   "outputs": [],
   "source": [
    "j_indices = []\n",
    "indptr = []\n",
    "values = []\n",
    "indptr.append(0)\n",
    "\n",
    "for i, doc in enumerate(movie_reviews.valid.x):\n",
    "    feature_counter = Counter(doc.data)\n",
    "    j_indices.extend(feature_counter.keys())\n",
    "    values.extend(feature_counter.values())\n",
    "    this_doc_ngrams = list()\n",
    "\n",
    "    m = 0\n",
    "    for n in range(min_n, max_n + 1):\n",
    "        for k in range(vocab_len - n + 1):\n",
    "            ngram = doc.data[k: k + n]\n",
    "            if str(ngram) in ngramtoi:\n",
    "                this_doc_ngrams.append(ngramtoi[str(ngram)])\n",
    "            m += 1\n",
    "\n",
    "    ngram_counter = Counter(this_doc_ngrams)\n",
    "    j_indices.extend(ngram_counter.keys())\n",
    "    values.extend(ngram_counter.values())\n",
    "    indptr.append(len(j_indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z2u7IxtWPdaR"
   },
   "outputs": [],
   "source": [
    "valid_ngram_doc_matrix = scipy.sparse.csr_matrix((values, j_indices, indptr),\n",
    "                                   shape=(len(indptr) - 1, len(ngramtoi)),\n",
    "                                   dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "Hh8gxmBCPdaS",
    "outputId": "18a04f07-1b0a-4269-8e74-156bac718e15"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<200x260374 sparse matrix of type '<class 'numpy.int32'>'\n",
       "\twith 121600 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_ngram_doc_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "Xn3jnhvGPdaS",
    "outputId": "90b6e396-1bc9-4a42-d1a9-de987cf52828"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<800x260374 sparse matrix of type '<class 'numpy.int32'>'\n",
       "\twith 678885 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ngram_doc_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_vl2rh1cPdaU"
   },
   "source": [
    "### Guardar matriz de n-gramas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nJ9QwQ_JPdaU"
   },
   "outputs": [],
   "source": [
    "scipy.sparse.save_npz(\"train_ngram_matrix.npz\", train_ngram_doc_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qYNGR4b7PdaV"
   },
   "outputs": [],
   "source": [
    "scipy.sparse.save_npz(\"valid_ngram_matrix.npz\", valid_ngram_doc_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yIZHjurlPdaW"
   },
   "outputs": [],
   "source": [
    "with open('itongram.pickle', 'wb') as handle:\n",
    "    pickle.dump(itongram, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open('ngramtoi.pickle', 'wb') as handle:\n",
    "    pickle.dump(itongram, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "heading_collapsed": true,
    "id": "j3Slx602PdaW"
   },
   "source": [
    "### Cargar matriz de n-gramas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "dZRLgGBLPdaX"
   },
   "outputs": [],
   "source": [
    "train_ngram_doc_matrix = scipy.sparse.load_npz(\"train_ngram_matrix.npz\")\n",
    "valid_ngram_doc_matrix = scipy.sparse.load_npz(\"valid_ngram_matrix.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "IS3MSxyQPdaY"
   },
   "outputs": [],
   "source": [
    "with open('itongram.pickle', 'rb') as handle:\n",
    "    b = pickle.load(handle)\n",
    "    \n",
    "with open('ngramtoi.pickle', 'rb') as handle:\n",
    "    b = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2bRIR344PdaY"
   },
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jfH6iz4LPdaZ"
   },
   "outputs": [],
   "source": [
    "x=train_ngram_doc_matrix\n",
    "y=movie_reviews.train.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AZU6EvepPdaa"
   },
   "outputs": [],
   "source": [
    "positive = y.c2i['positive']\n",
    "negative = y.c2i['negative']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "T_x2gyWfPdab",
    "outputId": "23f7f36e-efd1-4e1a-c27f-7a465e91b657"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<800x260374 sparse matrix of type '<class 'numpy.int32'>'\n",
       "\twith 678885 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z1A4LF-2Pdac"
   },
   "outputs": [],
   "source": [
    "k=260373"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UZ-bMlH8Pdac"
   },
   "outputs": [],
   "source": [
    "pos = (y.items == positive)[:k]\n",
    "neg = (y.items == negative)[:k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PByvZzCUPdae"
   },
   "outputs": [],
   "source": [
    "xx = x[:k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rd3NZ-e8Pdae"
   },
   "outputs": [],
   "source": [
    "valid_labels = [o == positive for o in movie_reviews.valid.y.items]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6fl1wgusPdaf"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-9ddefdb0ea58>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mp0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mneg\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mp1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpos\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "p0 = np.squeeze(np.array(xx[neg].sum(0)))\n",
    "p1 = np.squeeze(np.array(xx[pos].sum(0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eGyCtkRZPdah"
   },
   "outputs": [],
   "source": [
    "pr1 = (p1+1) / ((y.items==positive).sum() + 1)\n",
    "pr0 = (p0+1) / ((y.items==negative).sum() + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VUC7P8xaPdah"
   },
   "outputs": [],
   "source": [
    "r = np.log(pr1/pr0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B2RL-2ZhPdai"
   },
   "outputs": [],
   "source": [
    "b = np.log((y.items==positive).mean() / (y.items==negative).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "dcJ4VhqXPdak",
    "outputId": "513d19dc-1904-4ac5-960e-b60ef4967da8"
   },
   "outputs": [],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "e6TqfkoQPdal",
    "outputId": "4790cf5c-1bf6-48ac-f5fd-e97da18b1865"
   },
   "outputs": [],
   "source": [
    "(y.items==positive).mean(), (y.items==negative).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WIJvBL8PPdam"
   },
   "outputs": [],
   "source": [
    "pre_preds = valid_ngram_doc_matrix @ r.T + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "HFZzvqVdPdan",
    "outputId": "47e19d31-2c0e-4fdb-81ff-9a310d31b287"
   },
   "outputs": [],
   "source": [
    "pre_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7craIN9lPdan"
   },
   "outputs": [],
   "source": [
    "preds = pre_preds.T>0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "62f7c-XdPdap",
    "outputId": "f83a0f01-82f3-48ca-9252-fb15ab6ed2d2"
   },
   "outputs": [],
   "source": [
    "preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ST21UscAPdap"
   },
   "outputs": [],
   "source": [
    "valid_labels = [o == positive for o in movie_reviews.valid.y.items]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "girSkoOiPdaq",
    "outputId": "0d9ab1d0-f341-4a3b-a056-88bd4f40bd48"
   },
   "outputs": [],
   "source": [
    "(preds == valid_labels).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WvjyIpL7Pdar"
   },
   "source": [
    "### Naive Bayes Binarizado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DQ5f9AHzPdas"
   },
   "outputs": [],
   "source": [
    "trn_x_ngram_sgn = train_ngram_doc_matrix.sign()\n",
    "val_x_ngram_sgn = valid_ngram_doc_matrix.sign()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Gbdz3fXWPdau"
   },
   "outputs": [],
   "source": [
    "xx = trn_x_ngram_sgn[:k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "alBTdKC6Pdau"
   },
   "outputs": [],
   "source": [
    "p0 = np.squeeze(np.array(xx[neg].sum(0)))\n",
    "p1 = np.squeeze(np.array(xx[pos].sum(0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uOM3vNwmPdav"
   },
   "outputs": [],
   "source": [
    "pr1 = (p1+1) / ((y.items==positive).sum() + 1)\n",
    "pr0 = (p0+1) / ((y.items==negative).sum() + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3IQAjs7KPdaw"
   },
   "outputs": [],
   "source": [
    "r = np.log(pr1/pr0)\n",
    "b = np.log((y.items==positive).mean() / (y.items==negative).mean())\n",
    "\n",
    "pre_preds = val_x_ngram_sgn @ r.T + b\n",
    "preds = pre_preds.T>0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "p6UdkU_bPdax",
    "outputId": "91c5a3c9-7ef3-46c8-a44c-c326ea8818c0"
   },
   "outputs": [],
   "source": [
    "(preds==valid_labels).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "O0lpRVljPday"
   },
   "source": [
    "## Regresión Logística"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Qf-TWDloPdaz"
   },
   "source": [
    "Aquí ajustamos la regresión logística regularizada donde las características son los trigramas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MJIWpTrMPdaz"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Xqirv_AxPdaz"
   },
   "source": [
    "### usando CountVectorizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vFcx37S8Pda0"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MAZQxwoNPda0"
   },
   "outputs": [],
   "source": [
    "veczr = CountVectorizer(ngram_range=(1,3), preprocessor=noop, tokenizer=noop, max_features=800000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p0m0rc_3Pda1"
   },
   "outputs": [],
   "source": [
    "docs = movie_reviews.train.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G7xIRGkYPda2"
   },
   "outputs": [],
   "source": [
    "train_words = [[docs.vocab.itos[o] for o in doc.data] for doc in movie_reviews.train.x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QcSWBK2tPda3"
   },
   "outputs": [],
   "source": [
    "valid_words = [[docs.vocab.itos[o] for o in doc.data] for doc in movie_reviews.valid.x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "6audznBjPda4",
    "outputId": "b9e5402d-8fbc-4e4e-b12b-09a79154df54"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "train_ngram_doc = veczr.fit_transform(train_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "W2BLYtJ5Pda5",
    "outputId": "05ecfb47-6699-44a5-ff38-dd405c3705da",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_ngram_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "cpOKcxoEPda5",
    "outputId": "d536307d-eab5-4e42-8210-4eddada1a1cc",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "veczr.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YBOfzzQ4Pda7"
   },
   "outputs": [],
   "source": [
    "val_ngram_doc = veczr.transform(valid_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "N9nVpUMiPda8",
    "outputId": "6212779b-2eb3-4cc4-e3f9-0ef58c5173f1"
   },
   "outputs": [],
   "source": [
    "val_ngram_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uqvAkjUNPdbG"
   },
   "outputs": [],
   "source": [
    "vocab = veczr.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "sbE4HwTQPdbI",
    "outputId": "429a1526-50fc-4a77-cfa3-9038a26c8ba2"
   },
   "outputs": [],
   "source": [
    "vocab[200000:200005]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "p1nOv7bgPdbI"
   },
   "source": [
    "#### Naive Bayes binarizado usando ngrams y CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NMbXKSuJPdbJ"
   },
   "outputs": [],
   "source": [
    "y=movie_reviews.train.y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mP0m8RhOPdbK"
   },
   "source": [
    "C es la inversa de la fuerza de regularización; los valores más pequeños especifican una regularización más fuerte. Regularizado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "TkKdUGp4PdbK",
    "outputId": "ef236513-12f8-4455-cfe5-7461999b52d5"
   },
   "outputs": [],
   "source": [
    "m = LogisticRegression(C=0.1, dual=True)\n",
    "m.fit(train_ngram_doc.sign(), y.items);\n",
    "\n",
    "preds = m.predict(val_ngram_doc.sign())\n",
    "(preds.T==valid_labels).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PAo7mbJkPdbM"
   },
   "source": [
    "No binarizado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "TAA2fzTHPdbM",
    "outputId": "b2cedcb0-7c99-4272-fbb5-2d442acfb57e"
   },
   "outputs": [],
   "source": [
    "m = LogisticRegression(C=0.1, dual=True)\n",
    "m.fit(train_ngram_doc, y.items);\n",
    "\n",
    "preds = m.predict(val_ngram_doc)\n",
    "(preds.T==valid_labels).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yMWWkN0jPdbN"
   },
   "source": [
    "### Usando los ngrams, binarizado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 142
    },
    "colab_type": "code",
    "id": "7Z7Ub0H6PdbN",
    "outputId": "fc7533cd-4200-4a44-d230-1b35dfccd4a0"
   },
   "outputs": [],
   "source": [
    "m2 = LogisticRegression(C=0.1, dual=True)\n",
    "m2.fit(trn_x_ngram_sgn, y.items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "oXrKbLglPdbO",
    "outputId": "b42a1d3c-1473-4376-8a1f-aeb313c7642f"
   },
   "outputs": [],
   "source": [
    "preds = m2.predict(val_x_ngram_sgn)\n",
    "(preds.T==valid_labels).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HM5NjuZuPdbP"
   },
   "source": [
    "Se presenta un peor rendimiento cuando no está binarizado. Probé manualmente varios valores C diferentes, y este fue el mejor que encontraron los autores originales del notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 178
    },
    "colab_type": "code",
    "id": "ujStjKzPPdbP",
    "outputId": "ba1c8f6b-d151-4cd1-b4b3-02e05097efff"
   },
   "outputs": [],
   "source": [
    "m2 = LogisticRegression(C=0.0001, dual=True, max_iter=50000)\n",
    "m2.fit(train_ngram_doc_matrix, y.items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "5EkzqWStPdbQ",
    "outputId": "263f496e-d9fc-4ce2-8c93-ce1a56bdb161"
   },
   "outputs": [],
   "source": [
    "preds = m2.predict(valid_ngram_doc_matrix)\n",
    "(preds.T==valid_labels).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DqqEB5LBPdbR"
   },
   "source": [
    "### Log-count ratio\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KH7UagInPdbR"
   },
   "source": [
    "Aquí está el $\\text{log-count ratio}$ `r`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4VNWF5nSPdbS"
   },
   "outputs": [],
   "source": [
    "x=train_ngram_doc_matrix.sign()\n",
    "val_x=valid_ngram_doc_matrix.sign()\n",
    "y=movie_reviews.train.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lGL--q8fPdbT"
   },
   "outputs": [],
   "source": [
    "positive = y.c2i['positive']\n",
    "negative = y.c2i['negative']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JP5KNMxuPdbT"
   },
   "outputs": [],
   "source": [
    "k=260428"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KwknIZEMPdbU"
   },
   "outputs": [],
   "source": [
    "pos = (y.items == positive)[:k]\n",
    "neg = (y.items == negative)[:k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DdbpqHJTPdbV"
   },
   "outputs": [],
   "source": [
    "xx = x[:k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LcAyoEF9PdbV"
   },
   "outputs": [],
   "source": [
    "valid_labels = [o == positive for o in movie_reviews.valid.y.items]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P2OM7Z3APdbW"
   },
   "outputs": [],
   "source": [
    "p0 = np.squeeze(np.array(xx[neg].sum(0)))\n",
    "p1 = np.squeeze(np.array(xx[pos].sum(0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oaUmBwFiPdbY"
   },
   "outputs": [],
   "source": [
    "pr1 = (p1+1) / ((y.items==positive).sum() + 1)\n",
    "pr0 = (p0+1) / ((y.items==negative).sum() + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ucW7KGzjPdbY"
   },
   "outputs": [],
   "source": [
    "r = np.log(pr1/pr0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jgmMWhpwPdbZ"
   },
   "outputs": [],
   "source": [
    "b = np.log((y.items==positive).mean() / (y.items==negative).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "y6c_eH4GPdba",
    "outputId": "0daa8836-7ae3-4a4f-c4b4-6a07fa9822bd"
   },
   "outputs": [],
   "source": [
    "np.exp(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Yejvxg-nPdbb"
   },
   "source": [
    "Aquí ajustamos la regresión logística regularizada donde las características son las relaciones logarítmicas de los trigramas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 390
    },
    "colab_type": "code",
    "id": "R25vv86qPdbb",
    "outputId": "d43c3285-2813-484a-fdc3-d0912c840d99"
   },
   "outputs": [],
   "source": [
    "x_nb = xx.multiply(r)\n",
    "m = LogisticRegression(dual=True, C=0.1)\n",
    "m.fit(x_nb, y.items);\n",
    "\n",
    "val_x_nb = val_x.multiply(r)\n",
    "preds = m.predict(val_x_nb)\n",
    "(preds.T==valid_labels).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DMnX4o8dPdbc"
   },
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l4hfGlH_Pdbc"
   },
   "source": [
    "* Baselines and Bigrams: Simple, Good Sentiment and Topic Classification. Sida Wang and Christopher D. Manning [pdf](https://www.aclweb.org/anthology/P12-2018)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "3-logreg-nb-imdb.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
